{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982acb8f",
   "metadata": {},
   "source": [
    "## Siamese network \n",
    "Steps:\n",
    "1. load word embeding and document embedding\n",
    "2. create pytorch dataset and dataloader\n",
    "3. Try Contrastive loss and triplet loss\n",
    "4. further improve negative sampling (e.g. hard negative or word2vec negative sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42760b3",
   "metadata": {},
   "source": [
    "#### raw data\n",
    "* word embedding: glove\n",
    "* doc text: ./data/IMDB.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75d44e",
   "metadata": {},
   "source": [
    "### preprocess\n",
    "1. truncate smallest k word in IDF\n",
    "2. stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1843ac",
   "metadata": {},
   "source": [
    "### model\n",
    "1. k highest freq words\n",
    "2. CBOW\n",
    "3. Triplet\n",
    "4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9a2f89",
   "metadata": {},
   "source": [
    "### evaluation\n",
    "1. F1\n",
    "2. F1 weighted by TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e9beff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np \n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from itertools import cycle\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "49c5a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_document = 10000\n",
    "min_word_freq_threshold = 20\n",
    "topk_word_freq_threshold = 0\n",
    "document_vector_agg = 'mean'\n",
    "select_topk_TFIDF = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "05c1627d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1136aabeab624289bdba64f6dfa1d9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words:400000\n"
     ]
    }
   ],
   "source": [
    "# load word embedding\n",
    "embedding_file = \"../data/glove.6B.100d.txt\"\n",
    "\n",
    "word2embedding = dict()\n",
    "word_dim = int(re.findall(r\".(\\d+)d\",embedding_file)[0])\n",
    "\n",
    "with open(embedding_file,\"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        line = line.strip().split()\n",
    "        word = line[0]\n",
    "        embedding = list(map(float,line[1:]))\n",
    "        word2embedding[word] = embedding\n",
    "\n",
    "print(\"Number of words:%d\" % len(word2embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a1233053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, word2embedding, min_word_freq_threshold=0, topk_word_freq_threshold=0):\n",
    "        # The low frequency words will be assigned as <UNK> token\n",
    "        self.itos = {0: \"<UNK>\"}\n",
    "        self.stoi = {\"<UNK>\": 0}\n",
    "        self.word2embedding = word2embedding\n",
    "        self.min_word_freq_threshold = min_word_freq_threshold\n",
    "        self.topk_word_freq_threshold = topk_word_freq_threshold\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_eng(text):\n",
    "        text = re.sub(r'[^A-Za-z0-9 ]+', '', text)\n",
    "        return text.strip().split()\n",
    "\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        self.word_freq_in_corpus = defaultdict(int)\n",
    "        self.doc_freq = defaultdict(int) # # of document a word appear\n",
    "        self.document_num = len(sentence_list)\n",
    "        \n",
    "        self.word_vectors = [[0]*word_dim] # init zero padding\n",
    "        self.mask_word = set()\n",
    "        idx = 1\n",
    "        \n",
    "        for sentence in tqdm(sentence_list, desc=\"Preprocessing documents\"):\n",
    "            # for doc_freq\n",
    "            document_words = set()\n",
    "            \n",
    "            for word in self.tokenizer_eng(sentence):\n",
    "                # pass unknown word\n",
    "                if word not in self.word2embedding:\n",
    "                    continue\n",
    "                    \n",
    "                # calculate word freq\n",
    "                self.word_freq_in_corpus[word] += 1\n",
    "                \n",
    "                # validate word if it is more than min_word_freq_threshold times\n",
    "                if self.word_freq_in_corpus[word] == self.min_word_freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    self.word_vectors.append(self.word2embedding[word])\n",
    "                    idx += 1\n",
    "                \n",
    "                document_words.add(word)\n",
    "                \n",
    "            for word in document_words:\n",
    "                self.doc_freq[word] += 1\n",
    "        \n",
    "        # calculate IDF\n",
    "        self.IDF = {}\n",
    "        print('doc num', self.document_num)\n",
    "        for word, freq in self.doc_freq.items():\n",
    "            self.IDF[word] = math.log(self.document_num / (freq+1))\n",
    "        \n",
    "        # eliminate smallest K IDF words\n",
    "        IDF = [(word, freq) for word, freq in self.IDF.items()]\n",
    "        IDF.sort(key=lambda x: x[1])\n",
    "        \n",
    "        print('eliminate words')\n",
    "        for i in range(self.topk_word_freq_threshold):\n",
    "            if IDF[i][0] not in self.stoi:\n",
    "                continue\n",
    "            print(IDF[i][0])\n",
    "            idx = self.stoi[IDF[i][0]]\n",
    "            del self.stoi[IDF[i][0]]\n",
    "            del self.itos[idx]\n",
    "            del self.word_freq_in_corpus[IDF[i][0]]\n",
    "                \n",
    "    def calculate_document_vector(self, sentence_list, agg, select_topk_TFIDF=None):\n",
    "        document_vectors = []\n",
    "        document_answers = []\n",
    "        \n",
    "        for sentence in tqdm(sentence_list, desc=\"calculate document vectors\"):\n",
    "            document_vector = np.zeros(len(self.word_vectors[0]))\n",
    "            select_words = []\n",
    "            for word in self.tokenizer_eng(sentence):\n",
    "                # pass unknown word\n",
    "                if word not in self.stoi:\n",
    "                    continue\n",
    "                else:\n",
    "                    select_words.append(word)\n",
    "\n",
    "            # select topk TDIDF\n",
    "            if select_topk_TFIDF is not None:\n",
    "                doc_TFIDF = defaultdict(float)\n",
    "                for word in select_words:    \n",
    "                    doc_TFIDF[word] += self.IDF[word]\n",
    "\n",
    "                doc_TFIDF_l = [(word, TFIDF) for word, TFIDF in doc_TFIDF.items()]\n",
    "                doc_TFIDF_l.sort(key=lambda x:x[1], reverse=True)\n",
    "                \n",
    "                select_topk_words = set(list(map(lambda x:x[0], doc_TFIDF_l[:select_topk_TFIDF])))\n",
    "                select_words = [word for word in select_words if word in select_topk_words]\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # aggregate to doc vectors\n",
    "            for word in select_words:\n",
    "                if agg == 'mean':\n",
    "                    document_vector += self.word2embedding[word]\n",
    "                elif agg == 'TF-IDF':\n",
    "                    document_vector += np.array(self.word2embedding[word]) * self.IDF[word]\n",
    "\n",
    "            if len(select_words) == 0:\n",
    "                print('error', sentence)\n",
    "                return -1\n",
    "            else:\n",
    "                document_vector /= len(select_words)\n",
    "            \n",
    "            document_vectors.append(document_vector)\n",
    "            document_answers.append(select_words)\n",
    "        \n",
    "        # get answers\n",
    "        document_answers_idx = []    \n",
    "        for ans in document_answers:\n",
    "            ans_idx = []\n",
    "            for token in ans:\n",
    "                if token in self.stoi:\n",
    "                    ans_idx.append(self.stoi[token])                    \n",
    "            document_answers_idx.append(ans_idx)\n",
    "            \n",
    "        return document_vectors, document_answers_idx\n",
    "        \n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer_eng(text)\n",
    "\n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
    "            for token in tokenized_text\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1c5706a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBowDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 raw_data_file_path,\n",
    "                 word2embedding,\n",
    "                 skip_header = False,\n",
    "                 n_document = None, # read first n document\n",
    "                 min_word_freq_threshold = 20, # eliminate less freq words\n",
    "                 topk_word_freq_threshold = 5, # eliminate smallest k IDF words\n",
    "                 select_topk_TFIDF = None, # select topk tf-idf as ground-truth\n",
    "                 document_vector_agg = 'mean',\n",
    "                 ):\n",
    "\n",
    "        assert document_vector_agg in ['mean', 'TF-IDF']\n",
    "        \n",
    "        # raw documents\n",
    "        self.documents = []\n",
    "        # document vectors\n",
    "        self.document_vectors = []\n",
    "        \n",
    "        with open(raw_data_file_path,'r',encoding='utf-8') as f:\n",
    "            if skip_header:\n",
    "                f.readline()\n",
    "            for line in tqdm(f, desc=\"Loading documents\"):\n",
    "                # read firt n document\n",
    "                if n_document is not None and len(self.documents) >= n_document:\n",
    "                    break    \n",
    "                self.documents.append(line.strip(\"\\n\"))\n",
    "\n",
    "        # build vocabulary\n",
    "        self.vocab = Vocabulary(word2embedding, min_word_freq_threshold, topk_word_freq_threshold)\n",
    "        self.vocab.build_vocabulary(self.documents)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "#         self.words_tokenized = [self.vocab.numericalize(text) for text in self.documents]\n",
    "        \n",
    "        # calculate document vectors\n",
    "        self.document_vectors, self.words_tokenized = self.vocab.calculate_document_vector(self.documents, \\\n",
    "                                                                                           document_vector_agg, select_topk_TFIDF)\n",
    "        # train-test split\n",
    "        # training\n",
    "        self.train_length = int(len(self.words_tokenized)*0.8)\n",
    "        self.train_vectors = self.document_vectors[:self.train_length]\n",
    "        self.train_words = self.words_tokenized[:self.train_length]\n",
    "        self.document_ids = list(range(self.train_length))\n",
    "        self.generator = cycle(self.context_target_generator())\n",
    "        self.dataset_size = sum([len(s) for s in self.train_words])\n",
    "        \n",
    "        # testing\n",
    "        self.test_vectors = self.document_vectors[self.train_length:]\n",
    "        self.test_words = self.words_tokenized[self.train_length:]\n",
    "\n",
    "    def context_target_generator(self):\n",
    "        np.random.shuffle(self.document_ids) # inplace shuffle\n",
    "\n",
    "        # randomly select a document and create its training example\n",
    "        for document_id in self.document_ids: \n",
    "            word_list = set(self.train_words[document_id])\n",
    "            negative_sample_space = list(set(range(self.vocab_size)) - word_list)\n",
    "            negative_samples = np.random.choice(negative_sample_space,size=len(word_list),replace = False)\n",
    "            for word_id, negative_wordID in zip(word_list, negative_samples):\n",
    "                yield [document_id, word_id, negative_wordID]\n",
    "                \n",
    "    def __getitem__(self, idx):\n",
    "        doc_id, word_id, negative_wordID = next(self.generator)\n",
    "        doc_id = torch.FloatTensor(self.document_vectors[doc_id])\n",
    "        word_id = torch.FloatTensor(self.vocab.word_vectors[word_id])\n",
    "        negative_word = torch.FloatTensor(self.vocab.word_vectors[negative_wordID])\n",
    "\n",
    "        return doc_id, word_id, negative_word\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a1a7186c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff08e6ef3e843309f4cae248b03bd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading documents: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45411968c99644f2a67c387b7eda8970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing documents:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc num 10000\n",
      "eliminate words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32557630d324c5282c70ee8d40c4412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculate document vectors:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish building dataset!\n",
      "Number of documents:10000\n",
      "Number of words:7533\n"
     ]
    }
   ],
   "source": [
    "# load and build torch dataset\n",
    "data_file_path = '../data/IMDB.txt'\n",
    "\n",
    "print(\"Building dataset....\")\n",
    "dataset = CBowDataset(\n",
    "                    raw_data_file_path=data_file_path,\n",
    "                    word2embedding=word2embedding,\n",
    "                    skip_header=False,\n",
    "                    n_document = n_document,\n",
    "                    min_word_freq_threshold = min_word_freq_threshold,\n",
    "                    topk_word_freq_threshold = topk_word_freq_threshold,\n",
    "                    document_vector_agg = document_vector_agg,\n",
    "                    select_topk_TFIDF = select_topk_TFIDF\n",
    "                    )\n",
    "print(\"Finish building dataset!\")\n",
    "print(f\"Number of documents:{len(dataset.documents)}\")\n",
    "print(f\"Number of words:{dataset.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cf6bf5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 doc_vectors,\n",
    "                 ans_words,\n",
    "                 ):\n",
    "        self.doc_vectors = doc_vectors\n",
    "        self.ans_words = ans_words\n",
    "        assert len(doc_vectors) == len(ans_words)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        doc_vec = torch.FloatTensor(self.doc_vectors[idx])\n",
    "        ans_w = torch.tensor(list(set(self.ans_words[idx])))\n",
    "        return doc_vec, ans_w\n",
    "\n",
    "    def collate_fn(self,batch):\n",
    "        # Batch: List of tuples [(batch1), (batch2)]\n",
    "        \n",
    "        doc_vec = torch.cat([item[0].unsqueeze(0) for item in batch], dim=0)\n",
    "        ans_w = [item[1] for item in batch]\n",
    "        ans_w = pad_sequence(ans_w, batch_first=True, padding_value=-1)\n",
    "        \n",
    "        return doc_vec, ans_w \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.doc_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "457c5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, hdim):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(hdim, 256),\n",
    "                        nn.PReLU(),\n",
    "                        nn.Linear(256, 256),\n",
    "                        nn.PReLU(),\n",
    "                        nn.Linear(256, 2)\n",
    "                        )\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        output1 = self.fc(x1)\n",
    "        output2 = self.fc(x2)\n",
    "        output3 = self.fc(x3)\n",
    "        return output1, output2, output3\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "59ec9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplet loss\n",
    "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b60ca7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 1.\n",
    "BATCH_SIZE = 1024\n",
    "EPOCH = 300\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model = TripletNet(word_dim).to(device)\n",
    "loss_fn = TripletLoss(margin).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "22a934f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "                        dataset, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=4,\n",
    "                        shuffle=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2aa0290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docvec = dataset.test_vectors\n",
    "test_ans = dataset.test_words\n",
    "test_dataset = TestDataset(test_docvec,test_ans)\n",
    "test_loader = DataLoader(test_dataset,                         \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         collate_fn=test_dataset.collate_fn)\n",
    "word_embedding_tensor = torch.FloatTensor(dataset.vocab.word_vectors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "05bb89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_word_emb, loader,Ks = [50,100,150,200]):\n",
    "    avg_precision, avg_recall = [], []\n",
    "    for batch in test_loader:\n",
    "        batch = [item.to(device) for item in batch]\n",
    "        emb, ans = batch\n",
    "        emb = model.get_embedding(emb)\n",
    "        scores = torch.cdist(emb, test_word_emb)\n",
    "        ans_length = torch.sum((~ans.eq(-1)).float(), dim=-1)\n",
    "        mask = ~ans.eq(-1).unsqueeze(-1)\n",
    "        \n",
    "        # calculate precision and recall\n",
    "        tmp_pr, tmp_re = [],[]\n",
    "        for K in Ks:\n",
    "            top_indices = torch.argsort(scores,dim=1)[:,:K]\n",
    "            hit = top_indices.unsqueeze(-2) == ans.unsqueeze(-1)\n",
    "            hit = torch.sum((hit * mask).flatten(1),dim=-1)\n",
    "            precision = hit / K\n",
    "            recall = hit / ans_length\n",
    "            tmp_pr.append(precision)\n",
    "            tmp_re.append(recall)\n",
    "        tmp_pr = torch.stack(tmp_pr).T.detach().cpu().numpy().tolist()\n",
    "        tmp_re = torch.stack(tmp_re).T.detach().cpu().numpy().tolist()\n",
    "        avg_precision.extend(tmp_pr)\n",
    "        avg_recall.extend(tmp_re)\n",
    "        \n",
    "    avg_precision = np.mean(avg_precision,axis=0)\n",
    "    avg_recall = np.mean(avg_recall, axis=0)\n",
    "    for idx, kval in enumerate(Ks):\n",
    "        print(f\"[K={kval}] Precision:{avg_precision[idx]:.4f} Recall:{avg_recall[idx]:.4f}\")\n",
    "    return avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c124d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1684 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.322057\n",
      "[K=50] Precision:0.5557 Recall:0.2523\n",
      "[K=100] Precision:0.4120 Recall:0.3627\n",
      "[K=150] Precision:0.3307 Recall:0.4294\n",
      "[K=200] Precision:0.2791 Recall:0.4788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1684 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.311204\n",
      "[K=50] Precision:0.5526 Recall:0.2506\n",
      "[K=100] Precision:0.4097 Recall:0.3604\n",
      "[K=150] Precision:0.3316 Recall:0.4307\n",
      "[K=200] Precision:0.2807 Recall:0.4823\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1684 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.308062\n",
      "[K=50] Precision:0.5721 Recall:0.2596\n",
      "[K=100] Precision:0.4158 Recall:0.3657\n",
      "[K=150] Precision:0.3312 Recall:0.4305\n",
      "[K=200] Precision:0.2789 Recall:0.4796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1684 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-a332d75b24da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mavg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtual_env/py37/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtual_env/py37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    avg_loss = []\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = [item.to(device) for item in batch]\n",
    "        doc_id,pos_w,neg_w = batch\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(*model(doc_id,pos_w,neg_w))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss.append(loss.item())\n",
    "    avg_loss = np.mean(avg_loss)\n",
    "    print(f\"Loss:{avg_loss:4f}\")\n",
    "    \n",
    "    # evaluate\n",
    "    model.eval()\n",
    "    test_word_emb = model.get_embedding(word_embedding_tensor)\n",
    "    res = evaluate(test_word_emb,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cea5ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def evaluate_NDCG(test_word_emb, loader):\n",
    "    NDCGs = []\n",
    "    \n",
    "    for batch in tqdm(test_loader):\n",
    "        batch = [item.to(device) for item in batch]\n",
    "        emb, ans = batch\n",
    "        TFIDF_ans = np.zeros((len(ans), test_word_emb.shape[0]))\n",
    "        for i in range(len(ans)):\n",
    "            ans_row = ans[i]\n",
    "            ans_row = ans_row[~ans_row.eq(-1)]\n",
    "            for word_id in ans_row:\n",
    "                word_id = word_id.item()\n",
    "                word = dataset.vocab.itos[word_id]\n",
    "                TFIDF_ans[i][word_id] += dataset.vocab.IDF[word]\n",
    "             \n",
    "        emb = model.get_embedding(emb)\n",
    "        scores = -torch.cdist(emb, test_word_emb).cpu().detach().numpy()\n",
    "\n",
    "        true_relevance = TFIDF_ans\n",
    "        NDCG_score = ndcg_score(true_relevance, scores)\n",
    "        NDCGs.append(NDCG_score)\n",
    "        \n",
    "    \n",
    "    avg_NDCGs = np.mean(NDCGs)\n",
    "    print('avg_NDCG', avg_NDCGs)\n",
    "    return avg_NDCGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f340e005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed8682c88e045ec9ef1fd76c9abf989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_NDCG 0.4466589128981244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4466589128981244"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_NDCG(test_word_emb,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0606496c",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2bb80",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "96abe95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select > 0\n",
    "def metric1(binary_x, answer, verbose=0):\n",
    "    binary_x = binary_x > 0\n",
    "    pred = np.arange(len(binary_x))[binary_x]\n",
    "    \n",
    "    hit = np.intersect1d(pred, answer)\n",
    "    hit_num = len(hit)\n",
    "    recall = hit_num / len(answer)\n",
    "    precision = hit_num / len(pred)\n",
    "    if verbose == 1:\n",
    "        print('answer:', word_list[answer])\n",
    "        print('hit:', word_list[hit])    \n",
    "    return {\"recall\": recall, \"precision\": precision}\n",
    "\n",
    "# select > 0.5\n",
    "def metric2(binary_x, answer, th=0.5, verbose=0):\n",
    "#     binary_x = np.array([int(np.round(i)) for i in binary_x])\n",
    "    pred = np.arange(len(binary_x))[binary_x>=th]\n",
    "\n",
    "    hit = np.intersect1d(pred, answer)\n",
    "    hit_num = len(hit)\n",
    "    recall = hit_num / len(answer)\n",
    "    precision = hit_num / len(pred)\n",
    "    if verbose == 1:\n",
    "        print('answer:', word_list[answer])\n",
    "        print('hit:', word_list[hit])    \n",
    "    return {\"recall\": recall, \"precision\": precision}\n",
    "\n",
    "# select #answer largest pred\n",
    "def metric3(binary_x, answer, w_idx=None, scale=1, verbose=0):\n",
    "    select_num = int(len(answer) * scale)\n",
    "    if w_idx is not None:\n",
    "        pred = w_idx[np.argsort(binary_x)[-select_num:]]\n",
    "    else:\n",
    "        pred = np.arange(len(binary_x))[np.argsort(binary_x)[-select_num:]]\n",
    "    \n",
    "    hit = np.intersect1d(pred, answer)\n",
    "    hit_num = len(hit)\n",
    "    recall = hit_num / len(answer)\n",
    "    precision = hit_num / len(pred)\n",
    "    if verbose == 1:\n",
    "        print('answer:', word_list[answer])\n",
    "        print('hit:', word_list[hit])\n",
    "    return {\"recall\": recall, \"precision\": precision}\n",
    "\n",
    "# select #answer largest pred\n",
    "def metric4(binary_x, answer, w_idx=None, topk=50, verbose=0):\n",
    "    select_num = topk\n",
    "    answer = list(set(answer))\n",
    "    \n",
    "    if w_idx is not None:\n",
    "        pred = w_idx[np.argsort(binary_x)[-select_num:]]\n",
    "    else:\n",
    "        pred = np.arange(len(binary_x))[np.argsort(binary_x)[-select_num:]]\n",
    "    \n",
    "    hit = np.intersect1d(pred, answer)\n",
    "    hit_num = len(hit)\n",
    "    recall = hit_num / len(answer)\n",
    "    precision = hit_num / len(pred)\n",
    "    if verbose == 1:\n",
    "        print('answer:', word_list[answer])\n",
    "        print('hit:', word_list[hit])\n",
    "    return {\"recall\": recall, \"precision\": precision}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d536c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class PyTorchLinearRegression:\n",
    "    ''' Class that implemnets Multiple Linear Regression with PyTorch'''\n",
    "    def __init__(self, num_of_features, lr, constraintHigh, constraintLow, total, init_type=0, L1=0, L2=0):\n",
    "        if init_type == 0:\n",
    "            self.w = torch.zeros(num_of_features, requires_grad=True)\n",
    "        elif init_type == 1:\n",
    "            self.w = torch.ones(num_of_features, requires_grad=True)\n",
    "        elif init_type == 2:  \n",
    "            self.w = torch.rand(num_of_features, requires_grad=True)\n",
    "        elif init_type == 3:\n",
    "            self.w = -torch.ones(num_of_features, requires_grad=True)\n",
    "\n",
    "        self.learning_rate = lr\n",
    "        self.high = constraintHigh\n",
    "        self.low = constraintLow\n",
    "        self.total = total\n",
    "        self.rg2 = total / num_of_features\n",
    "        self.L1 = L1\n",
    "        self.L2 = L2\n",
    "        \n",
    "    def _model(self, X):\n",
    "        return X @ self.w.t()# + self.b\n",
    "    \n",
    "    def _mse(self, pred, real):\n",
    "        difference = pred - real\n",
    "        return torch.sum(difference * difference) / difference.numel()\n",
    "    \n",
    "    def _regularization_weightdist(self):\n",
    "        difference = self.w - 1\n",
    "        return -torch.sum(difference * difference) / difference.numel()\n",
    "    \n",
    "    def _regularization_weightsum(self):\n",
    "        difference = torch.sum(self.w) - self.total\n",
    "        return difference * difference / self.w.numel()\n",
    "        \n",
    "#     def _regularization_L1(self):\n",
    "#         return self.w.norm(1)#torch.sum(torch.abs(self.w))\n",
    "    \n",
    "#     def _regularization_L2(self):\n",
    "#         return self.w.norm(2)\n",
    "    \n",
    "    def fit(self, X, y, epochs):\n",
    "        print(loss_weight)\n",
    "        X = torch.from_numpy(X).float()\n",
    "        y = torch.from_numpy(y).float()\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            predictions = self._model(X)\n",
    "            loss1 = self._mse(predictions, y)\n",
    "            loss2 = self._regularization_weightdist()\n",
    "            loss3 = self._regularization_weightsum()\n",
    "            loss = loss1 * loss_weight[0] + loss2 * loss_weight[1] + loss3 * loss_weight[2]\n",
    "#             loss = loss1\n",
    "            \n",
    "            if (i % (epochs//20)) == 0:\n",
    "                print(f'Epoch: {i} - Loss: {loss1}')\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                self.w -= (self.w.grad) * self.learning_rate + torch.sign(self.w)*self.L1 + self.w*self.L2\n",
    "                self.w.grad.zero_()\n",
    "                self.w.data.clamp_(min=self.low, max=self.high)\n",
    "\n",
    "#             x = 100\n",
    "#             if i % x == x-1:\n",
    "# #                 self.w=torch.tensor(self.low + (self.high-self.low)*(self.w - torch.min(self.w))/(torch.max(self.w) - torch.min(self.w)), requires_grad=True)\n",
    "#                 self.w.data.clamp_(min=self.low, max=self.high)\n",
    "#                 pass\n",
    "                \n",
    "    def predict(self, X):\n",
    "        X = torch.from_numpy(X).float()\n",
    "        return self._model(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        X = torch.from_numpy(X).float()\n",
    "        y_pred = self._model(X).detach().numpy()\n",
    "        return r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a1ebb105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7533, 100)\n",
      "(10000, 100)\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "word_embs = np.array(dataset.vocab.word_vectors)\n",
    "doc_embs = np.array(dataset.document_vectors)\n",
    "doc_answers = dataset.words_tokenized\n",
    "word_list = dataset.vocab.itos\n",
    "\n",
    "print(word_embs.shape)\n",
    "print(doc_embs.shape)\n",
    "print(len(doc_answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d40353cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd352b5d0cd4b8390e2c751fe20126f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17827610671520233\n",
      "Epoch: 50 - Loss: 0.0025473786517977715\n",
      "Epoch: 100 - Loss: 0.0017679232405498624\n",
      "Epoch: 150 - Loss: 0.001450026291422546\n",
      "Epoch: 200 - Loss: 0.0012604641960933805\n",
      "Epoch: 250 - Loss: 0.001124239875935018\n",
      "Epoch: 300 - Loss: 0.001023078104481101\n",
      "Epoch: 350 - Loss: 0.0009503070032224059\n",
      "Epoch: 400 - Loss: 0.0008962148567661643\n",
      "Epoch: 450 - Loss: 0.0008509302278980613\n",
      "Epoch: 500 - Loss: 0.0008104497683234513\n",
      "Epoch: 550 - Loss: 0.0007780898595228791\n",
      "Epoch: 600 - Loss: 0.000749944883864373\n",
      "Epoch: 650 - Loss: 0.0007277996046468616\n",
      "Epoch: 700 - Loss: 0.0007051937282085419\n",
      "Epoch: 750 - Loss: 0.0006865779869258404\n",
      "Epoch: 800 - Loss: 0.0006683788960799575\n",
      "Epoch: 850 - Loss: 0.0006555995205417275\n",
      "Epoch: 900 - Loss: 0.0006414588424377143\n",
      "Epoch: 950 - Loss: 0.0006292320322245359\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17931674420833588\n",
      "Epoch: 50 - Loss: 0.0025776217225939035\n",
      "Epoch: 100 - Loss: 0.001732667675241828\n",
      "Epoch: 150 - Loss: 0.0013651929330080748\n",
      "Epoch: 200 - Loss: 0.0011433836771175265\n",
      "Epoch: 250 - Loss: 0.0009923692559823394\n",
      "Epoch: 300 - Loss: 0.0008814957109279931\n",
      "Epoch: 350 - Loss: 0.0007975741755217314\n",
      "Epoch: 400 - Loss: 0.0007343906327150762\n",
      "Epoch: 450 - Loss: 0.000685991020873189\n",
      "Epoch: 500 - Loss: 0.0006460000295192003\n",
      "Epoch: 550 - Loss: 0.0006129421526566148\n",
      "Epoch: 600 - Loss: 0.0005859927623532712\n",
      "Epoch: 650 - Loss: 0.0005646215286105871\n",
      "Epoch: 700 - Loss: 0.0005474876379594207\n",
      "Epoch: 750 - Loss: 0.0005324544617906213\n",
      "Epoch: 800 - Loss: 0.0005218064179643989\n",
      "Epoch: 850 - Loss: 0.0005115751991979778\n",
      "Epoch: 900 - Loss: 0.0005010509630665183\n",
      "Epoch: 950 - Loss: 0.0004924859385937452\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16367560625076294\n",
      "Epoch: 50 - Loss: 0.002112258691340685\n",
      "Epoch: 100 - Loss: 0.0014955892693251371\n",
      "Epoch: 150 - Loss: 0.0012229372514411807\n",
      "Epoch: 200 - Loss: 0.0010709748603403568\n",
      "Epoch: 250 - Loss: 0.0009662075317464769\n",
      "Epoch: 300 - Loss: 0.0008926989394240081\n",
      "Epoch: 350 - Loss: 0.0008340012864209712\n",
      "Epoch: 400 - Loss: 0.0007841759943403304\n",
      "Epoch: 450 - Loss: 0.0007493501179851592\n",
      "Epoch: 500 - Loss: 0.0007198753301054239\n",
      "Epoch: 550 - Loss: 0.0006947628571651876\n",
      "Epoch: 600 - Loss: 0.0006748804589733481\n",
      "Epoch: 650 - Loss: 0.0006584229413419962\n",
      "Epoch: 700 - Loss: 0.000641346035990864\n",
      "Epoch: 750 - Loss: 0.0006271489546634257\n",
      "Epoch: 800 - Loss: 0.0006145384977571666\n",
      "Epoch: 850 - Loss: 0.0006007062620483339\n",
      "Epoch: 900 - Loss: 0.0005905853467993438\n",
      "Epoch: 950 - Loss: 0.0005810986622236669\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1682918518781662\n",
      "Epoch: 50 - Loss: 0.0025474096182733774\n",
      "Epoch: 100 - Loss: 0.0018309276783838868\n",
      "Epoch: 150 - Loss: 0.0015314057236537337\n",
      "Epoch: 200 - Loss: 0.0013663587160408497\n",
      "Epoch: 250 - Loss: 0.0012565357610583305\n",
      "Epoch: 300 - Loss: 0.001169768744148314\n",
      "Epoch: 350 - Loss: 0.001097368192858994\n",
      "Epoch: 400 - Loss: 0.001037579495459795\n",
      "Epoch: 450 - Loss: 0.0009850567439571023\n",
      "Epoch: 500 - Loss: 0.0009418630506843328\n",
      "Epoch: 550 - Loss: 0.0009011028450913727\n",
      "Epoch: 600 - Loss: 0.0008648203802295029\n",
      "Epoch: 650 - Loss: 0.0008361166110262275\n",
      "Epoch: 700 - Loss: 0.0008118404657579958\n",
      "Epoch: 750 - Loss: 0.0007877320749685168\n",
      "Epoch: 800 - Loss: 0.0007708112825639546\n",
      "Epoch: 850 - Loss: 0.000752111547626555\n",
      "Epoch: 900 - Loss: 0.0007358219008892775\n",
      "Epoch: 950 - Loss: 0.0007165278657339513\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18204893171787262\n",
      "Epoch: 50 - Loss: 0.0025928509421646595\n",
      "Epoch: 100 - Loss: 0.0017884388798847795\n",
      "Epoch: 150 - Loss: 0.0014638382708653808\n",
      "Epoch: 200 - Loss: 0.0012785157887265086\n",
      "Epoch: 250 - Loss: 0.0011628629872575402\n",
      "Epoch: 300 - Loss: 0.0010791337117552757\n",
      "Epoch: 350 - Loss: 0.001012535416521132\n",
      "Epoch: 400 - Loss: 0.0009545197244733572\n",
      "Epoch: 450 - Loss: 0.0009064381010830402\n",
      "Epoch: 500 - Loss: 0.00086481764446944\n",
      "Epoch: 550 - Loss: 0.0008272861014120281\n",
      "Epoch: 600 - Loss: 0.000796823063865304\n",
      "Epoch: 650 - Loss: 0.0007691191858612001\n",
      "Epoch: 700 - Loss: 0.0007423784118145704\n",
      "Epoch: 750 - Loss: 0.0007194168865680695\n",
      "Epoch: 800 - Loss: 0.0006985480431467295\n",
      "Epoch: 850 - Loss: 0.0006835096864961088\n",
      "Epoch: 900 - Loss: 0.0006658054189756513\n",
      "Epoch: 950 - Loss: 0.0006503571639768779\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1617029905319214\n",
      "Epoch: 50 - Loss: 0.002045472152531147\n",
      "Epoch: 100 - Loss: 0.001496795448474586\n",
      "Epoch: 150 - Loss: 0.0012506963685154915\n",
      "Epoch: 200 - Loss: 0.001100489986129105\n",
      "Epoch: 250 - Loss: 0.0009894841350615025\n",
      "Epoch: 300 - Loss: 0.0009097065776586533\n",
      "Epoch: 350 - Loss: 0.0008460969547741115\n",
      "Epoch: 400 - Loss: 0.0007901465287432075\n",
      "Epoch: 450 - Loss: 0.0007402902701869607\n",
      "Epoch: 500 - Loss: 0.0007019006297923625\n",
      "Epoch: 550 - Loss: 0.0006725013954564929\n",
      "Epoch: 600 - Loss: 0.000646325119305402\n",
      "Epoch: 650 - Loss: 0.0006242941599339247\n",
      "Epoch: 700 - Loss: 0.0006052391836419702\n",
      "Epoch: 750 - Loss: 0.0005910795880481601\n",
      "Epoch: 800 - Loss: 0.000579335552174598\n",
      "Epoch: 850 - Loss: 0.0005662908079102635\n",
      "Epoch: 900 - Loss: 0.0005563537706620991\n",
      "Epoch: 950 - Loss: 0.0005481246626004577\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.15424858033657074\n",
      "Epoch: 50 - Loss: 0.0018639066256582737\n",
      "Epoch: 100 - Loss: 0.0014069050084799528\n",
      "Epoch: 150 - Loss: 0.0012197957839816809\n",
      "Epoch: 200 - Loss: 0.00111489393748343\n",
      "Epoch: 250 - Loss: 0.0010412329575046897\n",
      "Epoch: 300 - Loss: 0.000985518330708146\n",
      "Epoch: 350 - Loss: 0.000937239674385637\n",
      "Epoch: 400 - Loss: 0.0009011483052745461\n",
      "Epoch: 450 - Loss: 0.0008756768656894565\n",
      "Epoch: 500 - Loss: 0.0008501647389493883\n",
      "Epoch: 550 - Loss: 0.0008237102883867919\n",
      "Epoch: 600 - Loss: 0.0008070814656093717\n",
      "Epoch: 650 - Loss: 0.0007927842671051621\n",
      "Epoch: 700 - Loss: 0.0007722040172666311\n",
      "Epoch: 750 - Loss: 0.0007570902816951275\n",
      "Epoch: 800 - Loss: 0.0007451772107742727\n",
      "Epoch: 850 - Loss: 0.000728307815734297\n",
      "Epoch: 900 - Loss: 0.0007170233875513077\n",
      "Epoch: 950 - Loss: 0.0007085523684509099\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1409052312374115\n",
      "Epoch: 50 - Loss: 0.0017776823369786143\n",
      "Epoch: 100 - Loss: 0.0012859441339969635\n",
      "Epoch: 150 - Loss: 0.0010623696725815535\n",
      "Epoch: 200 - Loss: 0.0009258734644390643\n",
      "Epoch: 250 - Loss: 0.0008366554975509644\n",
      "Epoch: 300 - Loss: 0.0007776165148243308\n",
      "Epoch: 350 - Loss: 0.0007310750079341233\n",
      "Epoch: 400 - Loss: 0.0006936803692951798\n",
      "Epoch: 450 - Loss: 0.0006631180876865983\n",
      "Epoch: 500 - Loss: 0.0006394613301381469\n",
      "Epoch: 550 - Loss: 0.0006203723605722189\n",
      "Epoch: 600 - Loss: 0.0006042406894266605\n",
      "Epoch: 650 - Loss: 0.0005909466999582946\n",
      "Epoch: 700 - Loss: 0.0005786378169432282\n",
      "Epoch: 750 - Loss: 0.0005693691782653332\n",
      "Epoch: 800 - Loss: 0.0005638382863253355\n",
      "Epoch: 850 - Loss: 0.0005559248384088278\n",
      "Epoch: 900 - Loss: 0.0005484889261424541\n",
      "Epoch: 950 - Loss: 0.0005457039223983884\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.15368768572807312\n",
      "Epoch: 50 - Loss: 0.002320454688742757\n",
      "Epoch: 100 - Loss: 0.0016352602979168296\n",
      "Epoch: 150 - Loss: 0.001338494592346251\n",
      "Epoch: 200 - Loss: 0.0011611261870712042\n",
      "Epoch: 250 - Loss: 0.0010350889060646296\n",
      "Epoch: 300 - Loss: 0.0009432624210603535\n",
      "Epoch: 350 - Loss: 0.0008689345559105277\n",
      "Epoch: 400 - Loss: 0.0008075853693298995\n",
      "Epoch: 450 - Loss: 0.0007601514225825667\n",
      "Epoch: 500 - Loss: 0.0007230261689983308\n",
      "Epoch: 550 - Loss: 0.0006919939769431949\n",
      "Epoch: 600 - Loss: 0.0006653820746578276\n",
      "Epoch: 650 - Loss: 0.0006460079457610846\n",
      "Epoch: 700 - Loss: 0.0006247495184652507\n",
      "Epoch: 750 - Loss: 0.0006067490321584046\n",
      "Epoch: 800 - Loss: 0.0005920242983847857\n",
      "Epoch: 850 - Loss: 0.0005797774065285921\n",
      "Epoch: 900 - Loss: 0.000567898852750659\n",
      "Epoch: 950 - Loss: 0.0005562688456848264\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17186766862869263\n",
      "Epoch: 50 - Loss: 0.002141272649168968\n",
      "Epoch: 100 - Loss: 0.0014898980734869838\n",
      "Epoch: 150 - Loss: 0.0012101548491045833\n",
      "Epoch: 200 - Loss: 0.001042853924445808\n",
      "Epoch: 250 - Loss: 0.0009277832577936351\n",
      "Epoch: 300 - Loss: 0.0008450235472992063\n",
      "Epoch: 350 - Loss: 0.000773583771660924\n",
      "Epoch: 400 - Loss: 0.0007219622493721545\n",
      "Epoch: 450 - Loss: 0.0006768613820895553\n",
      "Epoch: 500 - Loss: 0.0006358912796713412\n",
      "Epoch: 550 - Loss: 0.0006062740576453507\n",
      "Epoch: 600 - Loss: 0.0005832035676576197\n",
      "Epoch: 650 - Loss: 0.0005629375809803605\n",
      "Epoch: 700 - Loss: 0.0005432463949546218\n",
      "Epoch: 750 - Loss: 0.0005276862066239119\n",
      "Epoch: 800 - Loss: 0.0005123384762555361\n",
      "Epoch: 850 - Loss: 0.0004992306930944324\n",
      "Epoch: 900 - Loss: 0.00048609208897687495\n",
      "Epoch: 950 - Loss: 0.0004760295560117811\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17186149954795837\n",
      "Epoch: 50 - Loss: 0.002132049761712551\n",
      "Epoch: 100 - Loss: 0.001563678728416562\n",
      "Epoch: 150 - Loss: 0.001330908271484077\n",
      "Epoch: 200 - Loss: 0.0011947037419304252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250 - Loss: 0.0011074277572333813\n",
      "Epoch: 300 - Loss: 0.0010322825983166695\n",
      "Epoch: 350 - Loss: 0.0009716759668663144\n",
      "Epoch: 400 - Loss: 0.0009281123639084399\n",
      "Epoch: 450 - Loss: 0.0008911907789297402\n",
      "Epoch: 500 - Loss: 0.0008642126340419054\n",
      "Epoch: 550 - Loss: 0.0008403874817304313\n",
      "Epoch: 600 - Loss: 0.0008194331894628704\n",
      "Epoch: 650 - Loss: 0.0008022725814953446\n",
      "Epoch: 700 - Loss: 0.0007856122683733702\n",
      "Epoch: 750 - Loss: 0.0007722590235061944\n",
      "Epoch: 800 - Loss: 0.0007598865195177495\n",
      "Epoch: 850 - Loss: 0.0007508056587539613\n",
      "Epoch: 900 - Loss: 0.0007410405669361353\n",
      "Epoch: 950 - Loss: 0.0007326100021600723\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1747533082962036\n",
      "Epoch: 50 - Loss: 0.0021771984174847603\n",
      "Epoch: 100 - Loss: 0.0014987352769821882\n",
      "Epoch: 150 - Loss: 0.0011870298767462373\n",
      "Epoch: 200 - Loss: 0.0010040339548140764\n",
      "Epoch: 250 - Loss: 0.0008834835607558489\n",
      "Epoch: 300 - Loss: 0.0007968731224536896\n",
      "Epoch: 350 - Loss: 0.0007320552249439061\n",
      "Epoch: 400 - Loss: 0.0006809664773754776\n",
      "Epoch: 450 - Loss: 0.0006422937149181962\n",
      "Epoch: 500 - Loss: 0.0006104566855356097\n",
      "Epoch: 550 - Loss: 0.0005866915453225374\n",
      "Epoch: 600 - Loss: 0.0005627205828204751\n",
      "Epoch: 650 - Loss: 0.000546608935110271\n",
      "Epoch: 700 - Loss: 0.0005317449104040861\n",
      "Epoch: 750 - Loss: 0.0005194241530261934\n",
      "Epoch: 800 - Loss: 0.0005087932804599404\n",
      "Epoch: 850 - Loss: 0.0004994023474864662\n",
      "Epoch: 900 - Loss: 0.000491392333060503\n",
      "Epoch: 950 - Loss: 0.0004834516439586878\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1611705720424652\n",
      "Epoch: 50 - Loss: 0.002291014650836587\n",
      "Epoch: 100 - Loss: 0.0016179138328880072\n",
      "Epoch: 150 - Loss: 0.0013311461079865694\n",
      "Epoch: 200 - Loss: 0.001158102066256106\n",
      "Epoch: 250 - Loss: 0.001039668102748692\n",
      "Epoch: 300 - Loss: 0.0009509554365649819\n",
      "Epoch: 350 - Loss: 0.0008823570678941905\n",
      "Epoch: 400 - Loss: 0.0008234165725298226\n",
      "Epoch: 450 - Loss: 0.0007768847281113267\n",
      "Epoch: 500 - Loss: 0.0007410515681840479\n",
      "Epoch: 550 - Loss: 0.0007114788750186563\n",
      "Epoch: 600 - Loss: 0.0006874953396618366\n",
      "Epoch: 650 - Loss: 0.0006680293590761721\n",
      "Epoch: 700 - Loss: 0.0006517464644275606\n",
      "Epoch: 750 - Loss: 0.0006386384484358132\n",
      "Epoch: 800 - Loss: 0.0006262543611228466\n",
      "Epoch: 850 - Loss: 0.0006161677301861346\n",
      "Epoch: 900 - Loss: 0.0006062667234800756\n",
      "Epoch: 950 - Loss: 0.0005956373061053455\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18332500755786896\n",
      "Epoch: 50 - Loss: 0.002271168166771531\n",
      "Epoch: 100 - Loss: 0.0016057074535638094\n",
      "Epoch: 150 - Loss: 0.001321918098255992\n",
      "Epoch: 200 - Loss: 0.0011585877509787679\n",
      "Epoch: 250 - Loss: 0.0010364038171246648\n",
      "Epoch: 300 - Loss: 0.0009520642925053835\n",
      "Epoch: 350 - Loss: 0.0008829680155031383\n",
      "Epoch: 400 - Loss: 0.0008282776107080281\n",
      "Epoch: 450 - Loss: 0.0007846559747122228\n",
      "Epoch: 500 - Loss: 0.0007511387811973691\n",
      "Epoch: 550 - Loss: 0.0007181864348240197\n",
      "Epoch: 600 - Loss: 0.0006933097611181438\n",
      "Epoch: 650 - Loss: 0.0006720917881466448\n",
      "Epoch: 700 - Loss: 0.0006539027672261\n",
      "Epoch: 750 - Loss: 0.0006375688826665282\n",
      "Epoch: 800 - Loss: 0.0006232720334082842\n",
      "Epoch: 850 - Loss: 0.0006109733367338777\n",
      "Epoch: 900 - Loss: 0.0005986890755593777\n",
      "Epoch: 950 - Loss: 0.0005910506006330252\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.20344169437885284\n",
      "Epoch: 50 - Loss: 0.0026977297384291887\n",
      "Epoch: 100 - Loss: 0.0019026279915124178\n",
      "Epoch: 150 - Loss: 0.0015900551807135344\n",
      "Epoch: 200 - Loss: 0.0014110858319327235\n",
      "Epoch: 250 - Loss: 0.0012860377319157124\n",
      "Epoch: 300 - Loss: 0.0011990460334345698\n",
      "Epoch: 350 - Loss: 0.0011285733198747039\n",
      "Epoch: 400 - Loss: 0.0010695606470108032\n",
      "Epoch: 450 - Loss: 0.0010225706500932574\n",
      "Epoch: 500 - Loss: 0.0009787729941308498\n",
      "Epoch: 550 - Loss: 0.0009432064252905548\n",
      "Epoch: 600 - Loss: 0.0009084314224310219\n",
      "Epoch: 650 - Loss: 0.0008795903413556516\n",
      "Epoch: 700 - Loss: 0.0008547875913791358\n",
      "Epoch: 750 - Loss: 0.0008364301756955683\n",
      "Epoch: 800 - Loss: 0.0008103041327558458\n",
      "Epoch: 850 - Loss: 0.0007900837226770818\n",
      "Epoch: 900 - Loss: 0.0007660908158868551\n",
      "Epoch: 950 - Loss: 0.0007440909976139665\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18588413298130035\n",
      "Epoch: 50 - Loss: 0.0023318384774029255\n",
      "Epoch: 100 - Loss: 0.0016164944972842932\n",
      "Epoch: 150 - Loss: 0.0013230247423052788\n",
      "Epoch: 200 - Loss: 0.001147550530731678\n",
      "Epoch: 250 - Loss: 0.0010370591189712286\n",
      "Epoch: 300 - Loss: 0.0009539340389892459\n",
      "Epoch: 350 - Loss: 0.0008923374698497355\n",
      "Epoch: 400 - Loss: 0.0008461344405077398\n",
      "Epoch: 450 - Loss: 0.0008057522936724126\n",
      "Epoch: 500 - Loss: 0.0007754459511488676\n",
      "Epoch: 550 - Loss: 0.0007503312663175166\n",
      "Epoch: 600 - Loss: 0.0007237650570459664\n",
      "Epoch: 650 - Loss: 0.0007065756362862885\n",
      "Epoch: 700 - Loss: 0.0006849533529020846\n",
      "Epoch: 750 - Loss: 0.0006734683993272483\n",
      "Epoch: 800 - Loss: 0.0006579815526492894\n",
      "Epoch: 850 - Loss: 0.0006493388209491968\n",
      "Epoch: 900 - Loss: 0.0006357208476401865\n",
      "Epoch: 950 - Loss: 0.0006280773086473346\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1626727432012558\n",
      "Epoch: 50 - Loss: 0.0020959980320185423\n",
      "Epoch: 100 - Loss: 0.001483479398302734\n",
      "Epoch: 150 - Loss: 0.0012105056084692478\n",
      "Epoch: 200 - Loss: 0.0010483493097126484\n",
      "Epoch: 250 - Loss: 0.0009351519984193146\n",
      "Epoch: 300 - Loss: 0.0008592962403781712\n",
      "Epoch: 350 - Loss: 0.0007971294689923525\n",
      "Epoch: 400 - Loss: 0.0007503845263272524\n",
      "Epoch: 450 - Loss: 0.0007109035504981875\n",
      "Epoch: 500 - Loss: 0.000679305347148329\n",
      "Epoch: 550 - Loss: 0.0006538109737448394\n",
      "Epoch: 600 - Loss: 0.0006347665330395103\n",
      "Epoch: 650 - Loss: 0.0006178306066431105\n",
      "Epoch: 700 - Loss: 0.0006015776307322085\n",
      "Epoch: 750 - Loss: 0.0005897656665183604\n",
      "Epoch: 800 - Loss: 0.0005778419435955584\n",
      "Epoch: 850 - Loss: 0.0005677235312759876\n",
      "Epoch: 900 - Loss: 0.000560905144084245\n",
      "Epoch: 950 - Loss: 0.000554147525690496\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1592739075422287\n",
      "Epoch: 50 - Loss: 0.0021298201754689217\n",
      "Epoch: 100 - Loss: 0.0014928336022421718\n",
      "Epoch: 150 - Loss: 0.0012124382192268968\n",
      "Epoch: 200 - Loss: 0.0010486411629244685\n",
      "Epoch: 250 - Loss: 0.0009349255124107003\n",
      "Epoch: 300 - Loss: 0.0008525677258148789\n",
      "Epoch: 350 - Loss: 0.0007880304474383593\n",
      "Epoch: 400 - Loss: 0.0007392854895442724\n",
      "Epoch: 450 - Loss: 0.0006974083371460438\n",
      "Epoch: 500 - Loss: 0.0006611341377720237\n",
      "Epoch: 550 - Loss: 0.0006319364183582366\n",
      "Epoch: 600 - Loss: 0.0006120761972852051\n",
      "Epoch: 650 - Loss: 0.0005956359091214836\n",
      "Epoch: 700 - Loss: 0.0005801943480037153\n",
      "Epoch: 750 - Loss: 0.000567988958209753\n",
      "Epoch: 800 - Loss: 0.0005554900853894651\n",
      "Epoch: 850 - Loss: 0.0005445401184260845\n",
      "Epoch: 900 - Loss: 0.0005356401088647544\n",
      "Epoch: 950 - Loss: 0.0005283476202748716\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18155501782894135\n",
      "Epoch: 50 - Loss: 0.002404944971203804\n",
      "Epoch: 100 - Loss: 0.0016681907000020146\n",
      "Epoch: 150 - Loss: 0.0013583434047177434\n",
      "Epoch: 200 - Loss: 0.0011916792718693614\n",
      "Epoch: 250 - Loss: 0.0010769094806164503\n",
      "Epoch: 300 - Loss: 0.0009878994897007942\n",
      "Epoch: 350 - Loss: 0.000917649595066905\n",
      "Epoch: 400 - Loss: 0.0008609307697042823\n",
      "Epoch: 450 - Loss: 0.0008115802775137126\n",
      "Epoch: 500 - Loss: 0.0007731654332019389\n",
      "Epoch: 550 - Loss: 0.0007431349367834628\n",
      "Epoch: 600 - Loss: 0.0007178926607593894\n",
      "Epoch: 650 - Loss: 0.0006937581347301602\n",
      "Epoch: 700 - Loss: 0.0006735919159837067\n",
      "Epoch: 750 - Loss: 0.0006568660610355437\n",
      "Epoch: 800 - Loss: 0.0006418414413928986\n",
      "Epoch: 850 - Loss: 0.000627615547273308\n",
      "Epoch: 900 - Loss: 0.0006174332229420543\n",
      "Epoch: 950 - Loss: 0.0006037114653736353\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1915837526321411\n",
      "Epoch: 50 - Loss: 0.002696145558729768\n",
      "Epoch: 100 - Loss: 0.0018852404318749905\n",
      "Epoch: 150 - Loss: 0.001548914355225861\n",
      "Epoch: 200 - Loss: 0.0013681489508599043\n",
      "Epoch: 250 - Loss: 0.0012598623288795352\n",
      "Epoch: 300 - Loss: 0.0011757405009120703\n",
      "Epoch: 350 - Loss: 0.001114764716476202\n",
      "Epoch: 400 - Loss: 0.0010614983038976789\n",
      "Epoch: 450 - Loss: 0.0010183545527979732\n",
      "Epoch: 500 - Loss: 0.0009785544825717807\n",
      "Epoch: 550 - Loss: 0.0009499296429567039\n",
      "Epoch: 600 - Loss: 0.0009219785570167005\n",
      "Epoch: 650 - Loss: 0.0008940809057094157\n",
      "Epoch: 700 - Loss: 0.0008689346723258495\n",
      "Epoch: 750 - Loss: 0.000849866250064224\n",
      "Epoch: 800 - Loss: 0.0008295234874822199\n",
      "Epoch: 850 - Loss: 0.0008116098470054567\n",
      "Epoch: 900 - Loss: 0.0007958830101415515\n",
      "Epoch: 950 - Loss: 0.0007808618829585612\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17243966460227966\n",
      "Epoch: 50 - Loss: 0.002144812373444438\n",
      "Epoch: 100 - Loss: 0.0015082043828442693\n",
      "Epoch: 150 - Loss: 0.0012424691813066602\n",
      "Epoch: 200 - Loss: 0.00109258817974478\n",
      "Epoch: 250 - Loss: 0.0009939755545929074\n",
      "Epoch: 300 - Loss: 0.0009190934360958636\n",
      "Epoch: 350 - Loss: 0.0008657323778606951\n",
      "Epoch: 400 - Loss: 0.0008154310053214431\n",
      "Epoch: 450 - Loss: 0.0007736310362815857\n",
      "Epoch: 500 - Loss: 0.0007404022035188973\n",
      "Epoch: 550 - Loss: 0.0007156063802540302\n",
      "Epoch: 600 - Loss: 0.0006877894629724324\n",
      "Epoch: 650 - Loss: 0.0006670300499536097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 700 - Loss: 0.0006487315404228866\n",
      "Epoch: 750 - Loss: 0.0006318443920463324\n",
      "Epoch: 800 - Loss: 0.0006137600285001099\n",
      "Epoch: 850 - Loss: 0.0005992481601424515\n",
      "Epoch: 900 - Loss: 0.0005861297249794006\n",
      "Epoch: 950 - Loss: 0.0005736635648645461\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16584837436676025\n",
      "Epoch: 50 - Loss: 0.0027074026875197887\n",
      "Epoch: 100 - Loss: 0.0018831308698281646\n",
      "Epoch: 150 - Loss: 0.0015532454708591104\n",
      "Epoch: 200 - Loss: 0.0013630569446831942\n",
      "Epoch: 250 - Loss: 0.0012291350867599249\n",
      "Epoch: 300 - Loss: 0.0011241261381655931\n",
      "Epoch: 350 - Loss: 0.0010476458119228482\n",
      "Epoch: 400 - Loss: 0.0009843426523730159\n",
      "Epoch: 450 - Loss: 0.0009321675170212984\n",
      "Epoch: 500 - Loss: 0.0008930459152907133\n",
      "Epoch: 550 - Loss: 0.0008595000253990293\n",
      "Epoch: 600 - Loss: 0.0008321077330037951\n",
      "Epoch: 650 - Loss: 0.0008067035814747214\n",
      "Epoch: 700 - Loss: 0.0007866839878261089\n",
      "Epoch: 750 - Loss: 0.0007673271466046572\n",
      "Epoch: 800 - Loss: 0.000750822713598609\n",
      "Epoch: 850 - Loss: 0.0007375401328317821\n",
      "Epoch: 900 - Loss: 0.0007242952124215662\n",
      "Epoch: 950 - Loss: 0.0007138377404771745\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1806744784116745\n",
      "Epoch: 50 - Loss: 0.002162952208891511\n",
      "Epoch: 100 - Loss: 0.0014506697189062834\n",
      "Epoch: 150 - Loss: 0.0011349630076438189\n",
      "Epoch: 200 - Loss: 0.0009466736228205264\n",
      "Epoch: 250 - Loss: 0.000824744172859937\n",
      "Epoch: 300 - Loss: 0.0007425216608680785\n",
      "Epoch: 350 - Loss: 0.0006831344217061996\n",
      "Epoch: 400 - Loss: 0.000636159791611135\n",
      "Epoch: 450 - Loss: 0.0006001570145599544\n",
      "Epoch: 500 - Loss: 0.0005724147777073085\n",
      "Epoch: 550 - Loss: 0.000549512158613652\n",
      "Epoch: 600 - Loss: 0.0005270865513011813\n",
      "Epoch: 650 - Loss: 0.0005074365180917084\n",
      "Epoch: 700 - Loss: 0.0004945781547576189\n",
      "Epoch: 750 - Loss: 0.00047939541400410235\n",
      "Epoch: 800 - Loss: 0.00046808450133539736\n",
      "Epoch: 850 - Loss: 0.00045817342470400035\n",
      "Epoch: 900 - Loss: 0.0004512013983912766\n",
      "Epoch: 950 - Loss: 0.00044442497892305255\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.11015449464321136\n",
      "Epoch: 50 - Loss: 0.002062036655843258\n",
      "Epoch: 100 - Loss: 0.001582263270393014\n",
      "Epoch: 150 - Loss: 0.0013803386827930808\n",
      "Epoch: 200 - Loss: 0.0012644195230677724\n",
      "Epoch: 250 - Loss: 0.0011865547858178616\n",
      "Epoch: 300 - Loss: 0.0011306991800665855\n",
      "Epoch: 350 - Loss: 0.001082367030903697\n",
      "Epoch: 400 - Loss: 0.0010457986500114202\n",
      "Epoch: 450 - Loss: 0.0010165323037654161\n",
      "Epoch: 500 - Loss: 0.0009866118198260665\n",
      "Epoch: 550 - Loss: 0.0009621993522159755\n",
      "Epoch: 600 - Loss: 0.0009467455674894154\n",
      "Epoch: 650 - Loss: 0.0009303726837970316\n",
      "Epoch: 700 - Loss: 0.000915331591386348\n",
      "Epoch: 750 - Loss: 0.0009065992198884487\n",
      "Epoch: 800 - Loss: 0.0008969743503257632\n",
      "Epoch: 850 - Loss: 0.000884900102391839\n",
      "Epoch: 900 - Loss: 0.0008817644556984305\n",
      "Epoch: 950 - Loss: 0.0008740967023186386\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16707584261894226\n",
      "Epoch: 50 - Loss: 0.0031520568300038576\n",
      "Epoch: 100 - Loss: 0.0022958528716117144\n",
      "Epoch: 150 - Loss: 0.0019519127672538161\n",
      "Epoch: 200 - Loss: 0.001751541392877698\n",
      "Epoch: 250 - Loss: 0.0016033477149903774\n",
      "Epoch: 300 - Loss: 0.001497687422670424\n",
      "Epoch: 350 - Loss: 0.0014128326438367367\n",
      "Epoch: 400 - Loss: 0.0013367240317165852\n",
      "Epoch: 450 - Loss: 0.0012769220629706979\n",
      "Epoch: 500 - Loss: 0.0012260950170457363\n",
      "Epoch: 550 - Loss: 0.0011807909468188882\n",
      "Epoch: 600 - Loss: 0.0011374469613656402\n",
      "Epoch: 650 - Loss: 0.0011039681266993284\n",
      "Epoch: 700 - Loss: 0.0010722115403041244\n",
      "Epoch: 750 - Loss: 0.001044895383529365\n",
      "Epoch: 800 - Loss: 0.0010221963748335838\n",
      "Epoch: 850 - Loss: 0.000999965937808156\n",
      "Epoch: 900 - Loss: 0.0009737685322761536\n",
      "Epoch: 950 - Loss: 0.000953775190282613\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18206340074539185\n",
      "Epoch: 50 - Loss: 0.00268142600543797\n",
      "Epoch: 100 - Loss: 0.0018573191482573748\n",
      "Epoch: 150 - Loss: 0.0015090686501935124\n",
      "Epoch: 200 - Loss: 0.001308340928517282\n",
      "Epoch: 250 - Loss: 0.0011667353101074696\n",
      "Epoch: 300 - Loss: 0.0010629906319081783\n",
      "Epoch: 350 - Loss: 0.0009894524700939655\n",
      "Epoch: 400 - Loss: 0.0009339028620161116\n",
      "Epoch: 450 - Loss: 0.0008867928991094232\n",
      "Epoch: 500 - Loss: 0.0008445940329693258\n",
      "Epoch: 550 - Loss: 0.0008097948157228529\n",
      "Epoch: 600 - Loss: 0.0007785987691022456\n",
      "Epoch: 650 - Loss: 0.0007523586391471326\n",
      "Epoch: 700 - Loss: 0.0007318542338907719\n",
      "Epoch: 750 - Loss: 0.0007131999591365457\n",
      "Epoch: 800 - Loss: 0.0006972945993766189\n",
      "Epoch: 850 - Loss: 0.000680995115544647\n",
      "Epoch: 900 - Loss: 0.000669044500682503\n",
      "Epoch: 950 - Loss: 0.0006565664662048221\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1801108717918396\n",
      "Epoch: 50 - Loss: 0.002427102066576481\n",
      "Epoch: 100 - Loss: 0.0017892633331939578\n",
      "Epoch: 150 - Loss: 0.001525802188552916\n",
      "Epoch: 200 - Loss: 0.0013678164687007666\n",
      "Epoch: 250 - Loss: 0.001252580899745226\n",
      "Epoch: 300 - Loss: 0.0011690255487337708\n",
      "Epoch: 350 - Loss: 0.0011014731135219336\n",
      "Epoch: 400 - Loss: 0.0010466121602803469\n",
      "Epoch: 450 - Loss: 0.0009976623114198446\n",
      "Epoch: 500 - Loss: 0.0009547026711516082\n",
      "Epoch: 550 - Loss: 0.0009235167526639998\n",
      "Epoch: 600 - Loss: 0.0008956813253462315\n",
      "Epoch: 650 - Loss: 0.0008700811304152012\n",
      "Epoch: 700 - Loss: 0.0008469056338071823\n",
      "Epoch: 750 - Loss: 0.000829491822514683\n",
      "Epoch: 800 - Loss: 0.0008098561083897948\n",
      "Epoch: 850 - Loss: 0.0007941562216728926\n",
      "Epoch: 900 - Loss: 0.0007792958640493453\n",
      "Epoch: 950 - Loss: 0.0007639548857696354\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18046359717845917\n",
      "Epoch: 50 - Loss: 0.0020872829481959343\n",
      "Epoch: 100 - Loss: 0.0014125385787338018\n",
      "Epoch: 150 - Loss: 0.0011293122079223394\n",
      "Epoch: 200 - Loss: 0.0009558178717270494\n",
      "Epoch: 250 - Loss: 0.0008397528436034918\n",
      "Epoch: 300 - Loss: 0.0007664316217415035\n",
      "Epoch: 350 - Loss: 0.0007185778813436627\n",
      "Epoch: 400 - Loss: 0.0006747605511918664\n",
      "Epoch: 450 - Loss: 0.0006421701400540769\n",
      "Epoch: 500 - Loss: 0.0006201842334121466\n",
      "Epoch: 550 - Loss: 0.0005960009875707328\n",
      "Epoch: 600 - Loss: 0.0005765525274910033\n",
      "Epoch: 650 - Loss: 0.0005594148533418775\n",
      "Epoch: 700 - Loss: 0.0005446434952318668\n",
      "Epoch: 750 - Loss: 0.0005327560938894749\n",
      "Epoch: 800 - Loss: 0.0005209195078350604\n",
      "Epoch: 850 - Loss: 0.0005125452298671007\n",
      "Epoch: 900 - Loss: 0.0005015735514461994\n",
      "Epoch: 950 - Loss: 0.0004956834600307047\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1740623116493225\n",
      "Epoch: 50 - Loss: 0.0024366716388612986\n",
      "Epoch: 100 - Loss: 0.0017526228912174702\n",
      "Epoch: 150 - Loss: 0.0014671863755211234\n",
      "Epoch: 200 - Loss: 0.001316067180596292\n",
      "Epoch: 250 - Loss: 0.0012117907172068954\n",
      "Epoch: 300 - Loss: 0.0011411323212087154\n",
      "Epoch: 350 - Loss: 0.0010816747089847922\n",
      "Epoch: 400 - Loss: 0.0010338443098589778\n",
      "Epoch: 450 - Loss: 0.0009944163030013442\n",
      "Epoch: 500 - Loss: 0.0009592470596544445\n",
      "Epoch: 550 - Loss: 0.0009287745342589915\n",
      "Epoch: 600 - Loss: 0.000904151878785342\n",
      "Epoch: 650 - Loss: 0.0008818124188110232\n",
      "Epoch: 700 - Loss: 0.0008647810900583863\n",
      "Epoch: 750 - Loss: 0.0008469752501696348\n",
      "Epoch: 800 - Loss: 0.0008320015040226281\n",
      "Epoch: 850 - Loss: 0.0008159428252838552\n",
      "Epoch: 900 - Loss: 0.0008019989472813904\n",
      "Epoch: 950 - Loss: 0.0007899252232164145\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1670219600200653\n",
      "Epoch: 50 - Loss: 0.0024683803785592318\n",
      "Epoch: 100 - Loss: 0.0017116025555878878\n",
      "Epoch: 150 - Loss: 0.001403755508363247\n",
      "Epoch: 200 - Loss: 0.0012317748041823506\n",
      "Epoch: 250 - Loss: 0.0011168770724907517\n",
      "Epoch: 300 - Loss: 0.0010272169020026922\n",
      "Epoch: 350 - Loss: 0.0009645872632972896\n",
      "Epoch: 400 - Loss: 0.0009091462125070393\n",
      "Epoch: 450 - Loss: 0.000870637537445873\n",
      "Epoch: 500 - Loss: 0.0008336027967743576\n",
      "Epoch: 550 - Loss: 0.0008031598990783095\n",
      "Epoch: 600 - Loss: 0.0007758684223517776\n",
      "Epoch: 650 - Loss: 0.0007527089328505099\n",
      "Epoch: 700 - Loss: 0.0007316377013921738\n",
      "Epoch: 750 - Loss: 0.0007169288583099842\n",
      "Epoch: 800 - Loss: 0.0007021889323368669\n",
      "Epoch: 850 - Loss: 0.0006881830631755292\n",
      "Epoch: 900 - Loss: 0.0006776314112357795\n",
      "Epoch: 950 - Loss: 0.0006664837710559368\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.2021166980266571\n",
      "Epoch: 50 - Loss: 0.002545071765780449\n",
      "Epoch: 100 - Loss: 0.0017872374737635255\n",
      "Epoch: 150 - Loss: 0.001479269121773541\n",
      "Epoch: 200 - Loss: 0.001294126850552857\n",
      "Epoch: 250 - Loss: 0.0011770938290283084\n",
      "Epoch: 300 - Loss: 0.0010901869973167777\n",
      "Epoch: 350 - Loss: 0.001021130825392902\n",
      "Epoch: 400 - Loss: 0.0009620502823963761\n",
      "Epoch: 450 - Loss: 0.0009190283599309623\n",
      "Epoch: 500 - Loss: 0.0008824705146253109\n",
      "Epoch: 550 - Loss: 0.0008499972755089402\n",
      "Epoch: 600 - Loss: 0.0008166139596141875\n",
      "Epoch: 650 - Loss: 0.0007857498712837696\n",
      "Epoch: 700 - Loss: 0.0007570731686428189\n",
      "Epoch: 750 - Loss: 0.0007359615992754698\n",
      "Epoch: 800 - Loss: 0.0007127709104679525\n",
      "Epoch: 850 - Loss: 0.0006908450741320848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 900 - Loss: 0.0006704070256091654\n",
      "Epoch: 950 - Loss: 0.0006537676090374589\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16816118359565735\n",
      "Epoch: 50 - Loss: 0.0023565683513879776\n",
      "Epoch: 100 - Loss: 0.0016410652315244079\n",
      "Epoch: 150 - Loss: 0.0013496286701411009\n",
      "Epoch: 200 - Loss: 0.0011838997015729547\n",
      "Epoch: 250 - Loss: 0.0010638957610353827\n",
      "Epoch: 300 - Loss: 0.00097485794685781\n",
      "Epoch: 350 - Loss: 0.0009060262236744165\n",
      "Epoch: 400 - Loss: 0.0008498824900016189\n",
      "Epoch: 450 - Loss: 0.0008046538569033146\n",
      "Epoch: 500 - Loss: 0.0007644615252502263\n",
      "Epoch: 550 - Loss: 0.000733960245270282\n",
      "Epoch: 600 - Loss: 0.0007076047477312386\n",
      "Epoch: 650 - Loss: 0.0006843068986199796\n",
      "Epoch: 700 - Loss: 0.0006653477903455496\n",
      "Epoch: 750 - Loss: 0.0006464075413532555\n",
      "Epoch: 800 - Loss: 0.0006318718660622835\n",
      "Epoch: 850 - Loss: 0.0006150745321065187\n",
      "Epoch: 900 - Loss: 0.0006012500962242484\n",
      "Epoch: 950 - Loss: 0.0005899625830352306\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.19794349372386932\n",
      "Epoch: 50 - Loss: 0.00261895009316504\n",
      "Epoch: 100 - Loss: 0.0018203600775450468\n",
      "Epoch: 150 - Loss: 0.0015060375444591045\n",
      "Epoch: 200 - Loss: 0.0013299188576638699\n",
      "Epoch: 250 - Loss: 0.001209888025186956\n",
      "Epoch: 300 - Loss: 0.0011237913277000189\n",
      "Epoch: 350 - Loss: 0.001059489673934877\n",
      "Epoch: 400 - Loss: 0.0010041161440312862\n",
      "Epoch: 450 - Loss: 0.0009595436858944595\n",
      "Epoch: 500 - Loss: 0.0009228013223037124\n",
      "Epoch: 550 - Loss: 0.0008866726420819759\n",
      "Epoch: 600 - Loss: 0.0008549464982934296\n",
      "Epoch: 650 - Loss: 0.0008223343174904585\n",
      "Epoch: 700 - Loss: 0.0007984319818206131\n",
      "Epoch: 750 - Loss: 0.0007756624254398048\n",
      "Epoch: 800 - Loss: 0.0007540980586782098\n",
      "Epoch: 850 - Loss: 0.0007403919007629156\n",
      "Epoch: 900 - Loss: 0.0007254190859384835\n",
      "Epoch: 950 - Loss: 0.0007064947276376188\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17922206223011017\n",
      "Epoch: 50 - Loss: 0.002681939397007227\n",
      "Epoch: 100 - Loss: 0.0018872043583542109\n",
      "Epoch: 150 - Loss: 0.0015823899302631617\n",
      "Epoch: 200 - Loss: 0.0013988612918183208\n",
      "Epoch: 250 - Loss: 0.0012941374443471432\n",
      "Epoch: 300 - Loss: 0.0012083188630640507\n",
      "Epoch: 350 - Loss: 0.0011399068171158433\n",
      "Epoch: 400 - Loss: 0.001084428164176643\n",
      "Epoch: 450 - Loss: 0.001034451648592949\n",
      "Epoch: 500 - Loss: 0.0009931294480338693\n",
      "Epoch: 550 - Loss: 0.0009596273303031921\n",
      "Epoch: 600 - Loss: 0.0009306332212872803\n",
      "Epoch: 650 - Loss: 0.0009010673966258764\n",
      "Epoch: 700 - Loss: 0.0008719897014088929\n",
      "Epoch: 750 - Loss: 0.0008464501006528735\n",
      "Epoch: 800 - Loss: 0.0008216598653234541\n",
      "Epoch: 850 - Loss: 0.0008001026581041515\n",
      "Epoch: 900 - Loss: 0.0007817368023097515\n",
      "Epoch: 950 - Loss: 0.0007635847432538867\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17273502051830292\n",
      "Epoch: 50 - Loss: 0.0024309614673256874\n",
      "Epoch: 100 - Loss: 0.0016778764547780156\n",
      "Epoch: 150 - Loss: 0.0013575478224083781\n",
      "Epoch: 200 - Loss: 0.001178828184492886\n",
      "Epoch: 250 - Loss: 0.0010591038735583425\n",
      "Epoch: 300 - Loss: 0.0009674714528955519\n",
      "Epoch: 350 - Loss: 0.000901003135368228\n",
      "Epoch: 400 - Loss: 0.0008476438233628869\n",
      "Epoch: 450 - Loss: 0.0008027394069358706\n",
      "Epoch: 500 - Loss: 0.0007671735947951674\n",
      "Epoch: 550 - Loss: 0.0007385829230770469\n",
      "Epoch: 600 - Loss: 0.0007098337518982589\n",
      "Epoch: 650 - Loss: 0.0006826402386650443\n",
      "Epoch: 700 - Loss: 0.0006637573824264109\n",
      "Epoch: 750 - Loss: 0.0006408981862477958\n",
      "Epoch: 800 - Loss: 0.0006248840363696218\n",
      "Epoch: 850 - Loss: 0.0006117129232734442\n",
      "Epoch: 900 - Loss: 0.0005974348168820143\n",
      "Epoch: 950 - Loss: 0.0005804265383630991\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.15961433947086334\n",
      "Epoch: 50 - Loss: 0.0022471994161605835\n",
      "Epoch: 100 - Loss: 0.001613542321138084\n",
      "Epoch: 150 - Loss: 0.0013368836371228099\n",
      "Epoch: 200 - Loss: 0.0011697027366608381\n",
      "Epoch: 250 - Loss: 0.0010583694092929363\n",
      "Epoch: 300 - Loss: 0.000973793095909059\n",
      "Epoch: 350 - Loss: 0.000907010049559176\n",
      "Epoch: 400 - Loss: 0.000854047539178282\n",
      "Epoch: 450 - Loss: 0.0008140535792335868\n",
      "Epoch: 500 - Loss: 0.0007820035680197179\n",
      "Epoch: 550 - Loss: 0.0007507232367061079\n",
      "Epoch: 600 - Loss: 0.0007242102874442935\n",
      "Epoch: 650 - Loss: 0.0007021728088147938\n",
      "Epoch: 700 - Loss: 0.0006862382870167494\n",
      "Epoch: 750 - Loss: 0.0006710977177135646\n",
      "Epoch: 800 - Loss: 0.0006581803900189698\n",
      "Epoch: 850 - Loss: 0.0006426945328712463\n",
      "Epoch: 900 - Loss: 0.0006343653658404946\n",
      "Epoch: 950 - Loss: 0.0006272670580074191\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1594971865415573\n",
      "Epoch: 50 - Loss: 0.002497295383363962\n",
      "Epoch: 100 - Loss: 0.0017188549973070621\n",
      "Epoch: 150 - Loss: 0.0014142119325697422\n",
      "Epoch: 200 - Loss: 0.001230785041116178\n",
      "Epoch: 250 - Loss: 0.0011110841296613216\n",
      "Epoch: 300 - Loss: 0.0010293893283233047\n",
      "Epoch: 350 - Loss: 0.0009627935942262411\n",
      "Epoch: 400 - Loss: 0.0009098008158616722\n",
      "Epoch: 450 - Loss: 0.0008641071617603302\n",
      "Epoch: 500 - Loss: 0.0008268516976386309\n",
      "Epoch: 550 - Loss: 0.0007940378854982555\n",
      "Epoch: 600 - Loss: 0.0007698212284594774\n",
      "Epoch: 650 - Loss: 0.000742701580747962\n",
      "Epoch: 700 - Loss: 0.0007234098156914115\n",
      "Epoch: 750 - Loss: 0.0007029192056506872\n",
      "Epoch: 800 - Loss: 0.0006876622792333364\n",
      "Epoch: 850 - Loss: 0.0006714792689308524\n",
      "Epoch: 900 - Loss: 0.0006611786666326225\n",
      "Epoch: 950 - Loss: 0.0006464376347139478\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1929035633802414\n",
      "Epoch: 50 - Loss: 0.002633505268022418\n",
      "Epoch: 100 - Loss: 0.0019235553918406367\n",
      "Epoch: 150 - Loss: 0.0016406417125836015\n",
      "Epoch: 200 - Loss: 0.0014723530039191246\n",
      "Epoch: 250 - Loss: 0.0013639398384839296\n",
      "Epoch: 300 - Loss: 0.0012820091797038913\n",
      "Epoch: 350 - Loss: 0.001217795885168016\n",
      "Epoch: 400 - Loss: 0.001171185402199626\n",
      "Epoch: 450 - Loss: 0.0011292635463178158\n",
      "Epoch: 500 - Loss: 0.00109261111356318\n",
      "Epoch: 550 - Loss: 0.0010628701420500875\n",
      "Epoch: 600 - Loss: 0.0010358921717852354\n",
      "Epoch: 650 - Loss: 0.00101039232686162\n",
      "Epoch: 700 - Loss: 0.0009870280046015978\n",
      "Epoch: 750 - Loss: 0.0009691843297332525\n",
      "Epoch: 800 - Loss: 0.0009507834911346436\n",
      "Epoch: 850 - Loss: 0.0009362457203678787\n",
      "Epoch: 900 - Loss: 0.0009236900368705392\n",
      "Epoch: 950 - Loss: 0.0009099712478928268\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1797810047864914\n",
      "Epoch: 50 - Loss: 0.002149307169020176\n",
      "Epoch: 100 - Loss: 0.0014996198005974293\n",
      "Epoch: 150 - Loss: 0.0012329426826909184\n",
      "Epoch: 200 - Loss: 0.0010749894427135587\n",
      "Epoch: 250 - Loss: 0.0009766651783138514\n",
      "Epoch: 300 - Loss: 0.0008977446123026311\n",
      "Epoch: 350 - Loss: 0.0008406570414081216\n",
      "Epoch: 400 - Loss: 0.0007967487908899784\n",
      "Epoch: 450 - Loss: 0.0007567491848021746\n",
      "Epoch: 500 - Loss: 0.0007229220354929566\n",
      "Epoch: 550 - Loss: 0.0006964845233596861\n",
      "Epoch: 600 - Loss: 0.0006739230593666434\n",
      "Epoch: 650 - Loss: 0.0006533144623972476\n",
      "Epoch: 700 - Loss: 0.0006380848353728652\n",
      "Epoch: 750 - Loss: 0.0006247221026569605\n",
      "Epoch: 800 - Loss: 0.0006112718838267028\n",
      "Epoch: 850 - Loss: 0.0006002187728881836\n",
      "Epoch: 900 - Loss: 0.000592513068113476\n",
      "Epoch: 950 - Loss: 0.0005828465800732374\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16528409719467163\n",
      "Epoch: 50 - Loss: 0.00236743432469666\n",
      "Epoch: 100 - Loss: 0.0016903710784390569\n",
      "Epoch: 150 - Loss: 0.0014332241844385862\n",
      "Epoch: 200 - Loss: 0.0012774330098181963\n",
      "Epoch: 250 - Loss: 0.0011756602907553315\n",
      "Epoch: 300 - Loss: 0.001096542808227241\n",
      "Epoch: 350 - Loss: 0.0010299087734892964\n",
      "Epoch: 400 - Loss: 0.000978164724074304\n",
      "Epoch: 450 - Loss: 0.0009335848735645413\n",
      "Epoch: 500 - Loss: 0.0008942175190895796\n",
      "Epoch: 550 - Loss: 0.0008599139982834458\n",
      "Epoch: 600 - Loss: 0.0008279916364699602\n",
      "Epoch: 650 - Loss: 0.0007966887787915766\n",
      "Epoch: 700 - Loss: 0.0007730961660854518\n",
      "Epoch: 750 - Loss: 0.0007507585105486214\n",
      "Epoch: 800 - Loss: 0.0007305924082174897\n",
      "Epoch: 850 - Loss: 0.0007142175454646349\n",
      "Epoch: 900 - Loss: 0.000699826458003372\n",
      "Epoch: 950 - Loss: 0.0006817291141487658\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.15825927257537842\n",
      "Epoch: 50 - Loss: 0.001972600119188428\n",
      "Epoch: 100 - Loss: 0.001437462866306305\n",
      "Epoch: 150 - Loss: 0.001201803213916719\n",
      "Epoch: 200 - Loss: 0.0010550923179835081\n",
      "Epoch: 250 - Loss: 0.0009608128457330167\n",
      "Epoch: 300 - Loss: 0.0008954463992267847\n",
      "Epoch: 350 - Loss: 0.0008428951259702444\n",
      "Epoch: 400 - Loss: 0.000800563779193908\n",
      "Epoch: 450 - Loss: 0.0007647461607120931\n",
      "Epoch: 500 - Loss: 0.0007357184076681733\n",
      "Epoch: 550 - Loss: 0.0007058225455693901\n",
      "Epoch: 600 - Loss: 0.0006839032284915447\n",
      "Epoch: 650 - Loss: 0.0006672947783954442\n",
      "Epoch: 700 - Loss: 0.0006530724349431694\n",
      "Epoch: 750 - Loss: 0.0006394971860572696\n",
      "Epoch: 800 - Loss: 0.0006296421634033322\n",
      "Epoch: 850 - Loss: 0.0006180137861520052\n",
      "Epoch: 900 - Loss: 0.0006066999048925936\n",
      "Epoch: 950 - Loss: 0.0006001575384289026\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17279461026191711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 - Loss: 0.002484549768269062\n",
      "Epoch: 100 - Loss: 0.0017592598451301455\n",
      "Epoch: 150 - Loss: 0.001465404755435884\n",
      "Epoch: 200 - Loss: 0.0013025104999542236\n",
      "Epoch: 250 - Loss: 0.0011879961239174008\n",
      "Epoch: 300 - Loss: 0.0011024209670722485\n",
      "Epoch: 350 - Loss: 0.0010280914139002562\n",
      "Epoch: 400 - Loss: 0.0009682632517069578\n",
      "Epoch: 450 - Loss: 0.0009182748035527766\n",
      "Epoch: 500 - Loss: 0.0008794620516709983\n",
      "Epoch: 550 - Loss: 0.0008440089295618236\n",
      "Epoch: 600 - Loss: 0.0008134423405863345\n",
      "Epoch: 650 - Loss: 0.000786221818998456\n",
      "Epoch: 700 - Loss: 0.0007624243735335767\n",
      "Epoch: 750 - Loss: 0.0007420868496410549\n",
      "Epoch: 800 - Loss: 0.0007224330329336226\n",
      "Epoch: 850 - Loss: 0.0007047282997518778\n",
      "Epoch: 900 - Loss: 0.0006919457809999585\n",
      "Epoch: 950 - Loss: 0.0006773598724976182\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18059608340263367\n",
      "Epoch: 50 - Loss: 0.002042071195319295\n",
      "Epoch: 100 - Loss: 0.0014313501305878162\n",
      "Epoch: 150 - Loss: 0.0011641350574791431\n",
      "Epoch: 200 - Loss: 0.0010123620741069317\n",
      "Epoch: 250 - Loss: 0.000905450142454356\n",
      "Epoch: 300 - Loss: 0.000828572316095233\n",
      "Epoch: 350 - Loss: 0.0007702010334469378\n",
      "Epoch: 400 - Loss: 0.0007206177106127143\n",
      "Epoch: 450 - Loss: 0.0006826728349551558\n",
      "Epoch: 500 - Loss: 0.0006522382609546185\n",
      "Epoch: 550 - Loss: 0.0006275699124671519\n",
      "Epoch: 600 - Loss: 0.0006057147402316332\n",
      "Epoch: 650 - Loss: 0.0005888655432499945\n",
      "Epoch: 700 - Loss: 0.0005738248582929373\n",
      "Epoch: 750 - Loss: 0.0005617362912744284\n",
      "Epoch: 800 - Loss: 0.0005502785788848996\n",
      "Epoch: 850 - Loss: 0.0005408775177784264\n",
      "Epoch: 900 - Loss: 0.0005331055726855993\n",
      "Epoch: 950 - Loss: 0.0005249339155852795\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17806708812713623\n",
      "Epoch: 50 - Loss: 0.0021699608769267797\n",
      "Epoch: 100 - Loss: 0.0015078755095601082\n",
      "Epoch: 150 - Loss: 0.001230041030794382\n",
      "Epoch: 200 - Loss: 0.0010694372467696667\n",
      "Epoch: 250 - Loss: 0.0009707601275295019\n",
      "Epoch: 300 - Loss: 0.0008991370559670031\n",
      "Epoch: 350 - Loss: 0.0008423759136348963\n",
      "Epoch: 400 - Loss: 0.0007984109106473625\n",
      "Epoch: 450 - Loss: 0.0007598501979373395\n",
      "Epoch: 500 - Loss: 0.0007297119009308517\n",
      "Epoch: 550 - Loss: 0.0006998575991019607\n",
      "Epoch: 600 - Loss: 0.0006779225659556687\n",
      "Epoch: 650 - Loss: 0.0006553693092428148\n",
      "Epoch: 700 - Loss: 0.0006377471145242453\n",
      "Epoch: 750 - Loss: 0.0006199419731274247\n",
      "Epoch: 800 - Loss: 0.0006099776946939528\n",
      "Epoch: 850 - Loss: 0.0005916670197620988\n",
      "Epoch: 900 - Loss: 0.0005816806224174798\n",
      "Epoch: 950 - Loss: 0.0005692209233529866\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1733797788619995\n",
      "Epoch: 50 - Loss: 0.002134346403181553\n",
      "Epoch: 100 - Loss: 0.0014825023245066404\n",
      "Epoch: 150 - Loss: 0.0012072951067239046\n",
      "Epoch: 200 - Loss: 0.0010463375365361571\n",
      "Epoch: 250 - Loss: 0.0009455733234062791\n",
      "Epoch: 300 - Loss: 0.0008699181489646435\n",
      "Epoch: 350 - Loss: 0.0008115038508549333\n",
      "Epoch: 400 - Loss: 0.0007642404525540769\n",
      "Epoch: 450 - Loss: 0.0007246287423186004\n",
      "Epoch: 500 - Loss: 0.0006976955337449908\n",
      "Epoch: 550 - Loss: 0.0006712478934787214\n",
      "Epoch: 600 - Loss: 0.0006511376705020666\n",
      "Epoch: 650 - Loss: 0.0006301006069406867\n",
      "Epoch: 700 - Loss: 0.0006154851871542633\n",
      "Epoch: 750 - Loss: 0.000600596540607512\n",
      "Epoch: 800 - Loss: 0.0005905774305574596\n",
      "Epoch: 850 - Loss: 0.0005796158220618963\n",
      "Epoch: 900 - Loss: 0.0005721814814023674\n",
      "Epoch: 950 - Loss: 0.0005636138375848532\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17044366896152496\n",
      "Epoch: 50 - Loss: 0.0023989719338715076\n",
      "Epoch: 100 - Loss: 0.0017013426404446363\n",
      "Epoch: 150 - Loss: 0.0014142505824565887\n",
      "Epoch: 200 - Loss: 0.0012579378671944141\n",
      "Epoch: 250 - Loss: 0.0011475459905341268\n",
      "Epoch: 300 - Loss: 0.0010654345387592912\n",
      "Epoch: 350 - Loss: 0.0009964508935809135\n",
      "Epoch: 400 - Loss: 0.0009416447719559073\n",
      "Epoch: 450 - Loss: 0.0008879739325493574\n",
      "Epoch: 500 - Loss: 0.0008408176945522428\n",
      "Epoch: 550 - Loss: 0.0007954934844747186\n",
      "Epoch: 600 - Loss: 0.0007601745892316103\n",
      "Epoch: 650 - Loss: 0.000729790423065424\n",
      "Epoch: 700 - Loss: 0.0007016150048002601\n",
      "Epoch: 750 - Loss: 0.0006741335964761674\n",
      "Epoch: 800 - Loss: 0.0006536450237035751\n",
      "Epoch: 850 - Loss: 0.0006345808506011963\n",
      "Epoch: 900 - Loss: 0.0006142939673736691\n",
      "Epoch: 950 - Loss: 0.0005985797033645213\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1706150621175766\n",
      "Epoch: 50 - Loss: 0.00228962698020041\n",
      "Epoch: 100 - Loss: 0.001599022769369185\n",
      "Epoch: 150 - Loss: 0.0013129604049026966\n",
      "Epoch: 200 - Loss: 0.0011435847263783216\n",
      "Epoch: 250 - Loss: 0.0010295239044353366\n",
      "Epoch: 300 - Loss: 0.0009439464774914086\n",
      "Epoch: 350 - Loss: 0.0008735525771044195\n",
      "Epoch: 400 - Loss: 0.0008178837015293539\n",
      "Epoch: 450 - Loss: 0.0007700383430346847\n",
      "Epoch: 500 - Loss: 0.000737312133423984\n",
      "Epoch: 550 - Loss: 0.0007060521747916937\n",
      "Epoch: 600 - Loss: 0.0006825429736636579\n",
      "Epoch: 650 - Loss: 0.0006618164479732513\n",
      "Epoch: 700 - Loss: 0.00064536661375314\n",
      "Epoch: 750 - Loss: 0.0006299649830907583\n",
      "Epoch: 800 - Loss: 0.0006171590648591518\n",
      "Epoch: 850 - Loss: 0.0006064507178962231\n",
      "Epoch: 900 - Loss: 0.0005952125648036599\n",
      "Epoch: 950 - Loss: 0.0005876767099834979\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.14844603836536407\n",
      "Epoch: 50 - Loss: 0.002317924750968814\n",
      "Epoch: 100 - Loss: 0.0017362406942993402\n",
      "Epoch: 150 - Loss: 0.0014806740218773484\n",
      "Epoch: 200 - Loss: 0.0013276509707793593\n",
      "Epoch: 250 - Loss: 0.0012112957192584872\n",
      "Epoch: 300 - Loss: 0.0011229350930079818\n",
      "Epoch: 350 - Loss: 0.0010565848788246512\n",
      "Epoch: 400 - Loss: 0.0010071102296933532\n",
      "Epoch: 450 - Loss: 0.0009562024497427046\n",
      "Epoch: 500 - Loss: 0.0009226562106050551\n",
      "Epoch: 550 - Loss: 0.0008941268897615373\n",
      "Epoch: 600 - Loss: 0.0008677584119141102\n",
      "Epoch: 650 - Loss: 0.0008442667312920094\n",
      "Epoch: 700 - Loss: 0.0008274759165942669\n",
      "Epoch: 750 - Loss: 0.0008050344767980278\n",
      "Epoch: 800 - Loss: 0.0007854258874431252\n",
      "Epoch: 850 - Loss: 0.0007742191082797945\n",
      "Epoch: 900 - Loss: 0.0007601049728691578\n",
      "Epoch: 950 - Loss: 0.000748062739148736\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.19190916419029236\n",
      "Epoch: 50 - Loss: 0.0024479145649820566\n",
      "Epoch: 100 - Loss: 0.0017260265303775668\n",
      "Epoch: 150 - Loss: 0.0014338776236400008\n",
      "Epoch: 200 - Loss: 0.0012758952798321843\n",
      "Epoch: 250 - Loss: 0.001172608812339604\n",
      "Epoch: 300 - Loss: 0.0010901144705712795\n",
      "Epoch: 350 - Loss: 0.0010302419541403651\n",
      "Epoch: 400 - Loss: 0.0009828652255237103\n",
      "Epoch: 450 - Loss: 0.0009391895146109164\n",
      "Epoch: 500 - Loss: 0.0008987068431451917\n",
      "Epoch: 550 - Loss: 0.0008675382123328745\n",
      "Epoch: 600 - Loss: 0.0008370654541067779\n",
      "Epoch: 650 - Loss: 0.0008084630826488137\n",
      "Epoch: 700 - Loss: 0.0007840613834559917\n",
      "Epoch: 750 - Loss: 0.0007598825031891465\n",
      "Epoch: 800 - Loss: 0.0007402285118587315\n",
      "Epoch: 850 - Loss: 0.0007212357013486326\n",
      "Epoch: 900 - Loss: 0.0007034564041532576\n",
      "Epoch: 950 - Loss: 0.0006918202270753682\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.179122194647789\n",
      "Epoch: 50 - Loss: 0.0028630823362618685\n",
      "Epoch: 100 - Loss: 0.0019862432964146137\n",
      "Epoch: 150 - Loss: 0.0016338618006557226\n",
      "Epoch: 200 - Loss: 0.0014113665092736483\n",
      "Epoch: 250 - Loss: 0.001266245380975306\n",
      "Epoch: 300 - Loss: 0.0011593479430302978\n",
      "Epoch: 350 - Loss: 0.0010724078165367246\n",
      "Epoch: 400 - Loss: 0.0010033503640443087\n",
      "Epoch: 450 - Loss: 0.000946546031627804\n",
      "Epoch: 500 - Loss: 0.0008969696355052292\n",
      "Epoch: 550 - Loss: 0.0008581256843172014\n",
      "Epoch: 600 - Loss: 0.0008229275699704885\n",
      "Epoch: 650 - Loss: 0.0007959343492984772\n",
      "Epoch: 700 - Loss: 0.0007700822316110134\n",
      "Epoch: 750 - Loss: 0.0007506633410230279\n",
      "Epoch: 800 - Loss: 0.0007336150156334043\n",
      "Epoch: 850 - Loss: 0.0007180275279097259\n",
      "Epoch: 900 - Loss: 0.0007037513423711061\n",
      "Epoch: 950 - Loss: 0.0006888256757520139\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1824968308210373\n",
      "Epoch: 50 - Loss: 0.002409612759947777\n",
      "Epoch: 100 - Loss: 0.0016771345399320126\n",
      "Epoch: 150 - Loss: 0.0013824101770296693\n",
      "Epoch: 200 - Loss: 0.001210646005347371\n",
      "Epoch: 250 - Loss: 0.001092651393264532\n",
      "Epoch: 300 - Loss: 0.001009825267829001\n",
      "Epoch: 350 - Loss: 0.00094745954265818\n",
      "Epoch: 400 - Loss: 0.0008932682685554028\n",
      "Epoch: 450 - Loss: 0.000849065138027072\n",
      "Epoch: 500 - Loss: 0.0008084388100542128\n",
      "Epoch: 550 - Loss: 0.0007748625939711928\n",
      "Epoch: 600 - Loss: 0.000744252058211714\n",
      "Epoch: 650 - Loss: 0.0007217257516458631\n",
      "Epoch: 700 - Loss: 0.0007003119681030512\n",
      "Epoch: 750 - Loss: 0.0006791624473407865\n",
      "Epoch: 800 - Loss: 0.0006624635425396264\n",
      "Epoch: 850 - Loss: 0.000647854758426547\n",
      "Epoch: 900 - Loss: 0.000631169241387397\n",
      "Epoch: 950 - Loss: 0.0006190045387484133\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18040086328983307\n",
      "Epoch: 50 - Loss: 0.002166168764233589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 - Loss: 0.0014710001414641738\n",
      "Epoch: 150 - Loss: 0.0011710218386724591\n",
      "Epoch: 200 - Loss: 0.0009983573108911514\n",
      "Epoch: 250 - Loss: 0.0008835679036565125\n",
      "Epoch: 300 - Loss: 0.0008063804125413299\n",
      "Epoch: 350 - Loss: 0.0007410216494463384\n",
      "Epoch: 400 - Loss: 0.000696481904014945\n",
      "Epoch: 450 - Loss: 0.0006600160268135369\n",
      "Epoch: 500 - Loss: 0.0006296074134297669\n",
      "Epoch: 550 - Loss: 0.000605473353061825\n",
      "Epoch: 600 - Loss: 0.0005857882788404822\n",
      "Epoch: 650 - Loss: 0.0005661834729835391\n",
      "Epoch: 700 - Loss: 0.0005483645363710821\n",
      "Epoch: 750 - Loss: 0.000534384569618851\n",
      "Epoch: 800 - Loss: 0.0005244703497737646\n",
      "Epoch: 850 - Loss: 0.0005153842503204942\n",
      "Epoch: 900 - Loss: 0.000507102464325726\n",
      "Epoch: 950 - Loss: 0.0004978244542144239\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.19884270429611206\n",
      "Epoch: 50 - Loss: 0.0028918650932610035\n",
      "Epoch: 100 - Loss: 0.0020153566729277372\n",
      "Epoch: 150 - Loss: 0.0016469416441395879\n",
      "Epoch: 200 - Loss: 0.0014326616656035185\n",
      "Epoch: 250 - Loss: 0.0012912581441923976\n",
      "Epoch: 300 - Loss: 0.0011918989475816488\n",
      "Epoch: 350 - Loss: 0.0011186745250597596\n",
      "Epoch: 400 - Loss: 0.0010583417024463415\n",
      "Epoch: 450 - Loss: 0.0010093246819451451\n",
      "Epoch: 500 - Loss: 0.000966015737503767\n",
      "Epoch: 550 - Loss: 0.0009270116570405662\n",
      "Epoch: 600 - Loss: 0.0008964011212810874\n",
      "Epoch: 650 - Loss: 0.0008662177715450525\n",
      "Epoch: 700 - Loss: 0.0008357189362868667\n",
      "Epoch: 750 - Loss: 0.0008090038318186998\n",
      "Epoch: 800 - Loss: 0.0007844088249839842\n",
      "Epoch: 850 - Loss: 0.0007586601423099637\n",
      "Epoch: 900 - Loss: 0.0007396064465865493\n",
      "Epoch: 950 - Loss: 0.000718949013389647\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1722370982170105\n",
      "Epoch: 50 - Loss: 0.0021767590660601854\n",
      "Epoch: 100 - Loss: 0.0014763999497517943\n",
      "Epoch: 150 - Loss: 0.0011651410022750497\n",
      "Epoch: 200 - Loss: 0.0009938596049323678\n",
      "Epoch: 250 - Loss: 0.00087965396232903\n",
      "Epoch: 300 - Loss: 0.0007985755219124258\n",
      "Epoch: 350 - Loss: 0.0007358890143223107\n",
      "Epoch: 400 - Loss: 0.0006880949367769063\n",
      "Epoch: 450 - Loss: 0.0006448626518249512\n",
      "Epoch: 500 - Loss: 0.0006118197343312204\n",
      "Epoch: 550 - Loss: 0.0005836263881064951\n",
      "Epoch: 600 - Loss: 0.0005609843647107482\n",
      "Epoch: 650 - Loss: 0.0005439435481093824\n",
      "Epoch: 700 - Loss: 0.0005274919094517827\n",
      "Epoch: 750 - Loss: 0.0005145954200997949\n",
      "Epoch: 800 - Loss: 0.0005030101165175438\n",
      "Epoch: 850 - Loss: 0.0004917027545161545\n",
      "Epoch: 900 - Loss: 0.00048394332407042384\n",
      "Epoch: 950 - Loss: 0.00047479651402682066\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17580583691596985\n",
      "Epoch: 50 - Loss: 0.0020874771289527416\n",
      "Epoch: 100 - Loss: 0.0014287936501204967\n",
      "Epoch: 150 - Loss: 0.0011559281265363097\n",
      "Epoch: 200 - Loss: 0.001004762714728713\n",
      "Epoch: 250 - Loss: 0.0008970259223133326\n",
      "Epoch: 300 - Loss: 0.0008241119212470949\n",
      "Epoch: 350 - Loss: 0.0007668297039344907\n",
      "Epoch: 400 - Loss: 0.0007189686875790358\n",
      "Epoch: 450 - Loss: 0.0006785158184356987\n",
      "Epoch: 500 - Loss: 0.000649715366307646\n",
      "Epoch: 550 - Loss: 0.000620621838606894\n",
      "Epoch: 600 - Loss: 0.000600466039031744\n",
      "Epoch: 650 - Loss: 0.0005844664410687983\n",
      "Epoch: 700 - Loss: 0.0005683323834091425\n",
      "Epoch: 750 - Loss: 0.0005560311255976558\n",
      "Epoch: 800 - Loss: 0.0005480605759657919\n",
      "Epoch: 850 - Loss: 0.0005392663297243416\n",
      "Epoch: 900 - Loss: 0.0005297783063724637\n",
      "Epoch: 950 - Loss: 0.0005212489049881697\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18427084386348724\n",
      "Epoch: 50 - Loss: 0.002318600658327341\n",
      "Epoch: 100 - Loss: 0.0015737024368718266\n",
      "Epoch: 150 - Loss: 0.001251924317330122\n",
      "Epoch: 200 - Loss: 0.001060277340002358\n",
      "Epoch: 250 - Loss: 0.0009304692503064871\n",
      "Epoch: 300 - Loss: 0.0008419865625910461\n",
      "Epoch: 350 - Loss: 0.0007754298858344555\n",
      "Epoch: 400 - Loss: 0.00072514294879511\n",
      "Epoch: 450 - Loss: 0.0006844151648692787\n",
      "Epoch: 500 - Loss: 0.0006522727780975401\n",
      "Epoch: 550 - Loss: 0.0006253963219933212\n",
      "Epoch: 600 - Loss: 0.0006001949077472091\n",
      "Epoch: 650 - Loss: 0.0005808852729387581\n",
      "Epoch: 700 - Loss: 0.0005630992236547172\n",
      "Epoch: 750 - Loss: 0.0005499131511896849\n",
      "Epoch: 800 - Loss: 0.0005351511645130813\n",
      "Epoch: 850 - Loss: 0.0005239470046944916\n",
      "Epoch: 900 - Loss: 0.0005132522201165557\n",
      "Epoch: 950 - Loss: 0.0005053642671555281\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.19046726822853088\n",
      "Epoch: 50 - Loss: 0.0022190576419234276\n",
      "Epoch: 100 - Loss: 0.0015422822907567024\n",
      "Epoch: 150 - Loss: 0.001250525820069015\n",
      "Epoch: 200 - Loss: 0.001086278585717082\n",
      "Epoch: 250 - Loss: 0.0009713072213344276\n",
      "Epoch: 300 - Loss: 0.0008868046570569277\n",
      "Epoch: 350 - Loss: 0.0008224318735301495\n",
      "Epoch: 400 - Loss: 0.0007743777241557837\n",
      "Epoch: 450 - Loss: 0.0007331589586101472\n",
      "Epoch: 500 - Loss: 0.0006942933541722596\n",
      "Epoch: 550 - Loss: 0.000662504113279283\n",
      "Epoch: 600 - Loss: 0.0006346869631670415\n",
      "Epoch: 650 - Loss: 0.0006132277194410563\n",
      "Epoch: 700 - Loss: 0.0005930779734626412\n",
      "Epoch: 750 - Loss: 0.0005780973006039858\n",
      "Epoch: 800 - Loss: 0.0005634286790154874\n",
      "Epoch: 850 - Loss: 0.0005514859221875668\n",
      "Epoch: 900 - Loss: 0.0005392259336076677\n",
      "Epoch: 950 - Loss: 0.0005279926117509604\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1561051309108734\n",
      "Epoch: 50 - Loss: 0.002570836339145899\n",
      "Epoch: 100 - Loss: 0.0018239798955619335\n",
      "Epoch: 150 - Loss: 0.0015125332865864038\n",
      "Epoch: 200 - Loss: 0.001341046066954732\n",
      "Epoch: 250 - Loss: 0.0012303165858611465\n",
      "Epoch: 300 - Loss: 0.0011551418574526906\n",
      "Epoch: 350 - Loss: 0.0011011314345523715\n",
      "Epoch: 400 - Loss: 0.0010567279532551765\n",
      "Epoch: 450 - Loss: 0.0010167271830141544\n",
      "Epoch: 500 - Loss: 0.000982013763859868\n",
      "Epoch: 550 - Loss: 0.000951091293245554\n",
      "Epoch: 600 - Loss: 0.0009200118365697563\n",
      "Epoch: 650 - Loss: 0.0008935854420997202\n",
      "Epoch: 700 - Loss: 0.0008728820248506963\n",
      "Epoch: 750 - Loss: 0.0008533947402611375\n",
      "Epoch: 800 - Loss: 0.0008356135222129524\n",
      "Epoch: 850 - Loss: 0.0008217851864174008\n",
      "Epoch: 900 - Loss: 0.0008077993406914175\n",
      "Epoch: 950 - Loss: 0.0007955912733450532\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.20068557560443878\n",
      "Epoch: 50 - Loss: 0.0027596489526331425\n",
      "Epoch: 100 - Loss: 0.0018797788070514798\n",
      "Epoch: 150 - Loss: 0.0015025879256427288\n",
      "Epoch: 200 - Loss: 0.0012934817932546139\n",
      "Epoch: 250 - Loss: 0.0011468816082924604\n",
      "Epoch: 300 - Loss: 0.001036094967275858\n",
      "Epoch: 350 - Loss: 0.0009553969139233232\n",
      "Epoch: 400 - Loss: 0.0008897916413843632\n",
      "Epoch: 450 - Loss: 0.0008412225288338959\n",
      "Epoch: 500 - Loss: 0.0008010215824469924\n",
      "Epoch: 550 - Loss: 0.000767734891269356\n",
      "Epoch: 600 - Loss: 0.0007390539976768196\n",
      "Epoch: 650 - Loss: 0.0007131992024369538\n",
      "Epoch: 700 - Loss: 0.000693641253747046\n",
      "Epoch: 750 - Loss: 0.0006743937847204506\n",
      "Epoch: 800 - Loss: 0.0006600853521376848\n",
      "Epoch: 850 - Loss: 0.0006445606704801321\n",
      "Epoch: 900 - Loss: 0.0006325104623101652\n",
      "Epoch: 950 - Loss: 0.0006221577641554177\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18512985110282898\n",
      "Epoch: 50 - Loss: 0.0036940083373337984\n",
      "Epoch: 100 - Loss: 0.0026486271526664495\n",
      "Epoch: 150 - Loss: 0.0022223431151360273\n",
      "Epoch: 200 - Loss: 0.0019744893070310354\n",
      "Epoch: 250 - Loss: 0.001795149757526815\n",
      "Epoch: 300 - Loss: 0.0016597717767581344\n",
      "Epoch: 350 - Loss: 0.0015432159416377544\n",
      "Epoch: 400 - Loss: 0.0014483435079455376\n",
      "Epoch: 450 - Loss: 0.001367328455671668\n",
      "Epoch: 500 - Loss: 0.0012987431837245822\n",
      "Epoch: 550 - Loss: 0.0012424723245203495\n",
      "Epoch: 600 - Loss: 0.0011924444697797298\n",
      "Epoch: 650 - Loss: 0.0011465491261333227\n",
      "Epoch: 700 - Loss: 0.00110749586019665\n",
      "Epoch: 750 - Loss: 0.0010720459977164865\n",
      "Epoch: 800 - Loss: 0.0010422177147120237\n",
      "Epoch: 850 - Loss: 0.001011880929581821\n",
      "Epoch: 900 - Loss: 0.0009860405698418617\n",
      "Epoch: 950 - Loss: 0.00096294772811234\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17378145456314087\n",
      "Epoch: 50 - Loss: 0.0020964748691767454\n",
      "Epoch: 100 - Loss: 0.001459337305277586\n",
      "Epoch: 150 - Loss: 0.001190903247334063\n",
      "Epoch: 200 - Loss: 0.0010414095595479012\n",
      "Epoch: 250 - Loss: 0.0009452968370169401\n",
      "Epoch: 300 - Loss: 0.0008827246492728591\n",
      "Epoch: 350 - Loss: 0.0008324261289089918\n",
      "Epoch: 400 - Loss: 0.0007909897249191999\n",
      "Epoch: 450 - Loss: 0.0007545517291873693\n",
      "Epoch: 500 - Loss: 0.0007280260324478149\n",
      "Epoch: 550 - Loss: 0.0007061287760734558\n",
      "Epoch: 600 - Loss: 0.0006893654353916645\n",
      "Epoch: 650 - Loss: 0.0006712317699566483\n",
      "Epoch: 700 - Loss: 0.0006566224037669599\n",
      "Epoch: 750 - Loss: 0.0006427565822377801\n",
      "Epoch: 800 - Loss: 0.0006274158367887139\n",
      "Epoch: 850 - Loss: 0.0006162287318147719\n",
      "Epoch: 900 - Loss: 0.0006071264506317675\n",
      "Epoch: 950 - Loss: 0.0005972745711915195\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1769827902317047\n",
      "Epoch: 50 - Loss: 0.00238058646209538\n",
      "Epoch: 100 - Loss: 0.0018294547917321324\n",
      "Epoch: 150 - Loss: 0.001608637860044837\n",
      "Epoch: 200 - Loss: 0.0014760909834876657\n",
      "Epoch: 250 - Loss: 0.0013761791633442044\n",
      "Epoch: 300 - Loss: 0.001302757766097784\n",
      "Epoch: 350 - Loss: 0.001250825123861432\n",
      "Epoch: 400 - Loss: 0.0012049966026097536\n",
      "Epoch: 450 - Loss: 0.0011634771944954991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500 - Loss: 0.0011278889141976833\n",
      "Epoch: 550 - Loss: 0.001095327315852046\n",
      "Epoch: 600 - Loss: 0.0010663222055882215\n",
      "Epoch: 650 - Loss: 0.0010421487968415022\n",
      "Epoch: 700 - Loss: 0.0010213416535407305\n",
      "Epoch: 750 - Loss: 0.0010029349941760302\n",
      "Epoch: 800 - Loss: 0.0009823970030993223\n",
      "Epoch: 850 - Loss: 0.0009675237815827131\n",
      "Epoch: 900 - Loss: 0.0009525562054477632\n",
      "Epoch: 950 - Loss: 0.0009373400243930519\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16304561495780945\n",
      "Epoch: 50 - Loss: 0.0024826182052493095\n",
      "Epoch: 100 - Loss: 0.001786702312529087\n",
      "Epoch: 150 - Loss: 0.0014980777632445097\n",
      "Epoch: 200 - Loss: 0.0013269054470583797\n",
      "Epoch: 250 - Loss: 0.0012112538097426295\n",
      "Epoch: 300 - Loss: 0.001124634756706655\n",
      "Epoch: 350 - Loss: 0.001051798346452415\n",
      "Epoch: 400 - Loss: 0.0009902145247906446\n",
      "Epoch: 450 - Loss: 0.0009409834165126085\n",
      "Epoch: 500 - Loss: 0.0009026575717143714\n",
      "Epoch: 550 - Loss: 0.0008742252830415964\n",
      "Epoch: 600 - Loss: 0.000845101079903543\n",
      "Epoch: 650 - Loss: 0.0008205960621125996\n",
      "Epoch: 700 - Loss: 0.0008033577469177544\n",
      "Epoch: 750 - Loss: 0.0007837103330530226\n",
      "Epoch: 800 - Loss: 0.0007666645105928183\n",
      "Epoch: 850 - Loss: 0.0007530368748120964\n",
      "Epoch: 900 - Loss: 0.0007368896040134132\n",
      "Epoch: 950 - Loss: 0.0007230901974253356\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.20131061971187592\n",
      "Epoch: 50 - Loss: 0.002663274295628071\n",
      "Epoch: 100 - Loss: 0.0018743718974292278\n",
      "Epoch: 150 - Loss: 0.001542063895612955\n",
      "Epoch: 200 - Loss: 0.0013565490953624249\n",
      "Epoch: 250 - Loss: 0.0012286907294765115\n",
      "Epoch: 300 - Loss: 0.0011360093485563993\n",
      "Epoch: 350 - Loss: 0.0010625113500282168\n",
      "Epoch: 400 - Loss: 0.001002538250759244\n",
      "Epoch: 450 - Loss: 0.0009479416767135262\n",
      "Epoch: 500 - Loss: 0.0009034466929733753\n",
      "Epoch: 550 - Loss: 0.000862620014231652\n",
      "Epoch: 600 - Loss: 0.0008295277366414666\n",
      "Epoch: 650 - Loss: 0.0007994500338099897\n",
      "Epoch: 700 - Loss: 0.0007700833957642317\n",
      "Epoch: 750 - Loss: 0.0007453345460817218\n",
      "Epoch: 800 - Loss: 0.0007250748458318412\n",
      "Epoch: 850 - Loss: 0.0007060859934426844\n",
      "Epoch: 900 - Loss: 0.0006888573407195508\n",
      "Epoch: 950 - Loss: 0.000676136405672878\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18927818536758423\n",
      "Epoch: 50 - Loss: 0.0024699715431779623\n",
      "Epoch: 100 - Loss: 0.0017474412452429533\n",
      "Epoch: 150 - Loss: 0.0014498410746455193\n",
      "Epoch: 200 - Loss: 0.0012749487068504095\n",
      "Epoch: 250 - Loss: 0.0011559500126168132\n",
      "Epoch: 300 - Loss: 0.0010738522978499532\n",
      "Epoch: 350 - Loss: 0.0010039206827059388\n",
      "Epoch: 400 - Loss: 0.0009485268383286893\n",
      "Epoch: 450 - Loss: 0.000901368330232799\n",
      "Epoch: 500 - Loss: 0.0008607360068708658\n",
      "Epoch: 550 - Loss: 0.0008214432164095342\n",
      "Epoch: 600 - Loss: 0.0007885587983764708\n",
      "Epoch: 650 - Loss: 0.0007588383741676807\n",
      "Epoch: 700 - Loss: 0.0007314232643693686\n",
      "Epoch: 750 - Loss: 0.0007082741940394044\n",
      "Epoch: 800 - Loss: 0.0006875008111819625\n",
      "Epoch: 850 - Loss: 0.0006663453532382846\n",
      "Epoch: 900 - Loss: 0.0006462509045377374\n",
      "Epoch: 950 - Loss: 0.0006318321684375405\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.158410906791687\n",
      "Epoch: 50 - Loss: 0.002309656934812665\n",
      "Epoch: 100 - Loss: 0.001617696601897478\n",
      "Epoch: 150 - Loss: 0.0013192597543820739\n",
      "Epoch: 200 - Loss: 0.0011473690392449498\n",
      "Epoch: 250 - Loss: 0.0010400449391454458\n",
      "Epoch: 300 - Loss: 0.0009574136347509921\n",
      "Epoch: 350 - Loss: 0.0008964057196862996\n",
      "Epoch: 400 - Loss: 0.0008441221434623003\n",
      "Epoch: 450 - Loss: 0.0008001051610335708\n",
      "Epoch: 500 - Loss: 0.000763324205763638\n",
      "Epoch: 550 - Loss: 0.0007357604335993528\n",
      "Epoch: 600 - Loss: 0.0007073667366057634\n",
      "Epoch: 650 - Loss: 0.0006860862486064434\n",
      "Epoch: 700 - Loss: 0.0006706083659082651\n",
      "Epoch: 750 - Loss: 0.0006553855491802096\n",
      "Epoch: 800 - Loss: 0.0006417680997401476\n",
      "Epoch: 850 - Loss: 0.000627764267846942\n",
      "Epoch: 900 - Loss: 0.0006149951950646937\n",
      "Epoch: 950 - Loss: 0.0006048892973922193\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17781850695610046\n",
      "Epoch: 50 - Loss: 0.0023381595965474844\n",
      "Epoch: 100 - Loss: 0.0016679124673828483\n",
      "Epoch: 150 - Loss: 0.001386853284202516\n",
      "Epoch: 200 - Loss: 0.0012352194171398878\n",
      "Epoch: 250 - Loss: 0.0011332255089655519\n",
      "Epoch: 300 - Loss: 0.0010607126168906689\n",
      "Epoch: 350 - Loss: 0.0009969425154849887\n",
      "Epoch: 400 - Loss: 0.0009466768824495375\n",
      "Epoch: 450 - Loss: 0.0009073820547200739\n",
      "Epoch: 500 - Loss: 0.0008724412182345986\n",
      "Epoch: 550 - Loss: 0.0008359724306501448\n",
      "Epoch: 600 - Loss: 0.000807371805422008\n",
      "Epoch: 650 - Loss: 0.0007818791200406849\n",
      "Epoch: 700 - Loss: 0.0007596542127430439\n",
      "Epoch: 750 - Loss: 0.0007395278662443161\n",
      "Epoch: 800 - Loss: 0.0007206976879388094\n",
      "Epoch: 850 - Loss: 0.0007034988957457244\n",
      "Epoch: 900 - Loss: 0.0006904806359671056\n",
      "Epoch: 950 - Loss: 0.0006792211788706481\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16694992780685425\n",
      "Epoch: 50 - Loss: 0.0025914800353348255\n",
      "Epoch: 100 - Loss: 0.0018380125984549522\n",
      "Epoch: 150 - Loss: 0.0015199349727481604\n",
      "Epoch: 200 - Loss: 0.0013318535638973117\n",
      "Epoch: 250 - Loss: 0.0012051929952576756\n",
      "Epoch: 300 - Loss: 0.0011081518605351448\n",
      "Epoch: 350 - Loss: 0.001031633117236197\n",
      "Epoch: 400 - Loss: 0.0009764030110090971\n",
      "Epoch: 450 - Loss: 0.0009286094573326409\n",
      "Epoch: 500 - Loss: 0.0008886320283636451\n",
      "Epoch: 550 - Loss: 0.0008521366980858147\n",
      "Epoch: 600 - Loss: 0.000820936867967248\n",
      "Epoch: 650 - Loss: 0.0007926412508822978\n",
      "Epoch: 700 - Loss: 0.0007704062154516578\n",
      "Epoch: 750 - Loss: 0.0007484635571017861\n",
      "Epoch: 800 - Loss: 0.0007277808617800474\n",
      "Epoch: 850 - Loss: 0.0007087974227033556\n",
      "Epoch: 900 - Loss: 0.0006948043592274189\n",
      "Epoch: 950 - Loss: 0.0006798639078624547\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.160127654671669\n",
      "Epoch: 50 - Loss: 0.0031617775093764067\n",
      "Epoch: 100 - Loss: 0.002338951453566551\n",
      "Epoch: 150 - Loss: 0.0019973302260041237\n",
      "Epoch: 200 - Loss: 0.0017877600621432066\n",
      "Epoch: 250 - Loss: 0.0016524530947208405\n",
      "Epoch: 300 - Loss: 0.0015580940525978804\n",
      "Epoch: 350 - Loss: 0.0014833039604127407\n",
      "Epoch: 400 - Loss: 0.0014215100090950727\n",
      "Epoch: 450 - Loss: 0.0013682263670489192\n",
      "Epoch: 500 - Loss: 0.001321389339864254\n",
      "Epoch: 550 - Loss: 0.0012813081266358495\n",
      "Epoch: 600 - Loss: 0.001246500527486205\n",
      "Epoch: 650 - Loss: 0.0012165919179096818\n",
      "Epoch: 700 - Loss: 0.0011876069474965334\n",
      "Epoch: 750 - Loss: 0.001164370565675199\n",
      "Epoch: 800 - Loss: 0.001137836487032473\n",
      "Epoch: 850 - Loss: 0.0011145585449412465\n",
      "Epoch: 900 - Loss: 0.0010948124108836055\n",
      "Epoch: 950 - Loss: 0.001077000517398119\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16711904108524323\n",
      "Epoch: 50 - Loss: 0.0024615987204015255\n",
      "Epoch: 100 - Loss: 0.0017897139769047499\n",
      "Epoch: 150 - Loss: 0.0015060704899951816\n",
      "Epoch: 200 - Loss: 0.0013468452962115407\n",
      "Epoch: 250 - Loss: 0.00123599951621145\n",
      "Epoch: 300 - Loss: 0.0011616683332249522\n",
      "Epoch: 350 - Loss: 0.0010999194346368313\n",
      "Epoch: 400 - Loss: 0.0010416952427476645\n",
      "Epoch: 450 - Loss: 0.0009981676703318954\n",
      "Epoch: 500 - Loss: 0.0009593170834705234\n",
      "Epoch: 550 - Loss: 0.0009253443568013608\n",
      "Epoch: 600 - Loss: 0.0008960706181824207\n",
      "Epoch: 650 - Loss: 0.000867533846758306\n",
      "Epoch: 700 - Loss: 0.0008420490194112062\n",
      "Epoch: 750 - Loss: 0.0008206658530980349\n",
      "Epoch: 800 - Loss: 0.0007978894282132387\n",
      "Epoch: 850 - Loss: 0.000778800982516259\n",
      "Epoch: 900 - Loss: 0.0007630320033058524\n",
      "Epoch: 950 - Loss: 0.0007487546536140144\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17207440733909607\n",
      "Epoch: 50 - Loss: 0.00259885611012578\n",
      "Epoch: 100 - Loss: 0.0018328194273635745\n",
      "Epoch: 150 - Loss: 0.0015265612164512277\n",
      "Epoch: 200 - Loss: 0.0013466686941683292\n",
      "Epoch: 250 - Loss: 0.0012334701605141163\n",
      "Epoch: 300 - Loss: 0.0011478075757622719\n",
      "Epoch: 350 - Loss: 0.0010750704677775502\n",
      "Epoch: 400 - Loss: 0.0010238905670121312\n",
      "Epoch: 450 - Loss: 0.0009767177980393171\n",
      "Epoch: 500 - Loss: 0.0009362445562146604\n",
      "Epoch: 550 - Loss: 0.0009043544996529818\n",
      "Epoch: 600 - Loss: 0.0008774069137871265\n",
      "Epoch: 650 - Loss: 0.0008533085347153246\n",
      "Epoch: 700 - Loss: 0.000831911398563534\n",
      "Epoch: 750 - Loss: 0.0008129958296194673\n",
      "Epoch: 800 - Loss: 0.0007909071282483637\n",
      "Epoch: 850 - Loss: 0.000776845496147871\n",
      "Epoch: 900 - Loss: 0.0007631786284036934\n",
      "Epoch: 950 - Loss: 0.0007479637861251831\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16028374433517456\n",
      "Epoch: 50 - Loss: 0.002811115700751543\n",
      "Epoch: 100 - Loss: 0.002014301950111985\n",
      "Epoch: 150 - Loss: 0.0016736435936763883\n",
      "Epoch: 200 - Loss: 0.0014650035882368684\n",
      "Epoch: 250 - Loss: 0.001323085161857307\n",
      "Epoch: 300 - Loss: 0.001223860657773912\n",
      "Epoch: 350 - Loss: 0.0011412982130423188\n",
      "Epoch: 400 - Loss: 0.0010750555666163564\n",
      "Epoch: 450 - Loss: 0.0010242349235340953\n",
      "Epoch: 500 - Loss: 0.0009812001371756196\n",
      "Epoch: 550 - Loss: 0.000945423380471766\n",
      "Epoch: 600 - Loss: 0.0009143619099631906\n",
      "Epoch: 650 - Loss: 0.000886497029569\n",
      "Epoch: 700 - Loss: 0.0008607507334090769\n",
      "Epoch: 750 - Loss: 0.0008407460991293192\n",
      "Epoch: 800 - Loss: 0.0008222931646741927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 850 - Loss: 0.0008061318076215684\n",
      "Epoch: 900 - Loss: 0.000790842401329428\n",
      "Epoch: 950 - Loss: 0.000776616099756211\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1888064593076706\n",
      "Epoch: 50 - Loss: 0.0027573055122047663\n",
      "Epoch: 100 - Loss: 0.0018675258615985513\n",
      "Epoch: 150 - Loss: 0.001497673336416483\n",
      "Epoch: 200 - Loss: 0.0012769411550834775\n",
      "Epoch: 250 - Loss: 0.0011370584834367037\n",
      "Epoch: 300 - Loss: 0.0010339929722249508\n",
      "Epoch: 350 - Loss: 0.0009522709297016263\n",
      "Epoch: 400 - Loss: 0.0008894415223039687\n",
      "Epoch: 450 - Loss: 0.0008369356510229409\n",
      "Epoch: 500 - Loss: 0.000795426603872329\n",
      "Epoch: 550 - Loss: 0.0007611719775013626\n",
      "Epoch: 600 - Loss: 0.0007322314195334911\n",
      "Epoch: 650 - Loss: 0.0007067622500471771\n",
      "Epoch: 700 - Loss: 0.0006815873784944415\n",
      "Epoch: 750 - Loss: 0.0006615808815695345\n",
      "Epoch: 800 - Loss: 0.0006468411302193999\n",
      "Epoch: 850 - Loss: 0.0006305871065706015\n",
      "Epoch: 900 - Loss: 0.0006146127125248313\n",
      "Epoch: 950 - Loss: 0.0006053465767763555\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18492966890335083\n",
      "Epoch: 50 - Loss: 0.002568139461800456\n",
      "Epoch: 100 - Loss: 0.0017533974023535848\n",
      "Epoch: 150 - Loss: 0.0013972471933811903\n",
      "Epoch: 200 - Loss: 0.0011870721355080605\n",
      "Epoch: 250 - Loss: 0.0010502043878659606\n",
      "Epoch: 300 - Loss: 0.0009513072436675429\n",
      "Epoch: 350 - Loss: 0.0008737828466109931\n",
      "Epoch: 400 - Loss: 0.0008086682646535337\n",
      "Epoch: 450 - Loss: 0.0007629907922819257\n",
      "Epoch: 500 - Loss: 0.0007263206061907113\n",
      "Epoch: 550 - Loss: 0.0006932875257916749\n",
      "Epoch: 600 - Loss: 0.0006665659020654857\n",
      "Epoch: 650 - Loss: 0.000642449944280088\n",
      "Epoch: 700 - Loss: 0.0006228298880159855\n",
      "Epoch: 750 - Loss: 0.0006030427757650614\n",
      "Epoch: 800 - Loss: 0.0005875486531294882\n",
      "Epoch: 850 - Loss: 0.0005749725387431681\n",
      "Epoch: 900 - Loss: 0.0005592014640569687\n",
      "Epoch: 950 - Loss: 0.0005511015187948942\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1653914898633957\n",
      "Epoch: 50 - Loss: 0.002376402262598276\n",
      "Epoch: 100 - Loss: 0.0017363567603752017\n",
      "Epoch: 150 - Loss: 0.0014751097187399864\n",
      "Epoch: 200 - Loss: 0.001328689861111343\n",
      "Epoch: 250 - Loss: 0.0012354247737675905\n",
      "Epoch: 300 - Loss: 0.0011622302699834108\n",
      "Epoch: 350 - Loss: 0.001102016307413578\n",
      "Epoch: 400 - Loss: 0.0010534904431551695\n",
      "Epoch: 450 - Loss: 0.0010117647470906377\n",
      "Epoch: 500 - Loss: 0.0009768212912604213\n",
      "Epoch: 550 - Loss: 0.0009479740401729941\n",
      "Epoch: 600 - Loss: 0.00092416099505499\n",
      "Epoch: 650 - Loss: 0.0009013909730128944\n",
      "Epoch: 700 - Loss: 0.0008801710791885853\n",
      "Epoch: 750 - Loss: 0.0008615745464339852\n",
      "Epoch: 800 - Loss: 0.0008467562729492784\n",
      "Epoch: 850 - Loss: 0.000833800295367837\n",
      "Epoch: 900 - Loss: 0.0008208201616071165\n",
      "Epoch: 950 - Loss: 0.0008088472532108426\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18133458495140076\n",
      "Epoch: 50 - Loss: 0.0023685877677053213\n",
      "Epoch: 100 - Loss: 0.001707468880340457\n",
      "Epoch: 150 - Loss: 0.0014151162467896938\n",
      "Epoch: 200 - Loss: 0.001241520163603127\n",
      "Epoch: 250 - Loss: 0.0011213385732844472\n",
      "Epoch: 300 - Loss: 0.0010328299831598997\n",
      "Epoch: 350 - Loss: 0.0009641379001550376\n",
      "Epoch: 400 - Loss: 0.0009150406694971025\n",
      "Epoch: 450 - Loss: 0.0008754365844652057\n",
      "Epoch: 500 - Loss: 0.0008416194468736649\n",
      "Epoch: 550 - Loss: 0.0008177708950825036\n",
      "Epoch: 600 - Loss: 0.0007908125990070403\n",
      "Epoch: 650 - Loss: 0.0007687999168410897\n",
      "Epoch: 700 - Loss: 0.0007426981464959681\n",
      "Epoch: 750 - Loss: 0.0007232424686662853\n",
      "Epoch: 800 - Loss: 0.0007037624018266797\n",
      "Epoch: 850 - Loss: 0.0006899047875776887\n",
      "Epoch: 900 - Loss: 0.0006757160881534219\n",
      "Epoch: 950 - Loss: 0.0006607739487662911\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.19400277733802795\n",
      "Epoch: 50 - Loss: 0.0025762508157640696\n",
      "Epoch: 100 - Loss: 0.00177931843791157\n",
      "Epoch: 150 - Loss: 0.001433508237823844\n",
      "Epoch: 200 - Loss: 0.0012360847322270274\n",
      "Epoch: 250 - Loss: 0.0010996931232511997\n",
      "Epoch: 300 - Loss: 0.0010022830683737993\n",
      "Epoch: 350 - Loss: 0.0009260043734684587\n",
      "Epoch: 400 - Loss: 0.0008637983119115233\n",
      "Epoch: 450 - Loss: 0.0008177999989129603\n",
      "Epoch: 500 - Loss: 0.0007767925271764398\n",
      "Epoch: 550 - Loss: 0.0007443425129167736\n",
      "Epoch: 600 - Loss: 0.0007124676485545933\n",
      "Epoch: 650 - Loss: 0.0006846383330412209\n",
      "Epoch: 700 - Loss: 0.0006581279449164867\n",
      "Epoch: 750 - Loss: 0.0006360675906762481\n",
      "Epoch: 800 - Loss: 0.0006147758103907108\n",
      "Epoch: 850 - Loss: 0.0005983013543300331\n",
      "Epoch: 900 - Loss: 0.0005850871675647795\n",
      "Epoch: 950 - Loss: 0.0005738266045227647\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.16315563023090363\n",
      "Epoch: 50 - Loss: 0.002537567401304841\n",
      "Epoch: 100 - Loss: 0.001831504050642252\n",
      "Epoch: 150 - Loss: 0.0015367093728855252\n",
      "Epoch: 200 - Loss: 0.0013583801919594407\n",
      "Epoch: 250 - Loss: 0.0012389509938657284\n",
      "Epoch: 300 - Loss: 0.0011510145850479603\n",
      "Epoch: 350 - Loss: 0.001080511836335063\n",
      "Epoch: 400 - Loss: 0.001029175240546465\n",
      "Epoch: 450 - Loss: 0.0009853265946730971\n",
      "Epoch: 500 - Loss: 0.0009467345662415028\n",
      "Epoch: 550 - Loss: 0.0009157866006717086\n",
      "Epoch: 600 - Loss: 0.0008845091797411442\n",
      "Epoch: 650 - Loss: 0.0008595319814048707\n",
      "Epoch: 700 - Loss: 0.0008344517555087805\n",
      "Epoch: 750 - Loss: 0.0008128625340759754\n",
      "Epoch: 800 - Loss: 0.0007911922293715179\n",
      "Epoch: 850 - Loss: 0.0007740105502307415\n",
      "Epoch: 900 - Loss: 0.0007544381660409272\n",
      "Epoch: 950 - Loss: 0.0007372075342573225\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1800687462091446\n",
      "Epoch: 50 - Loss: 0.002367190318182111\n",
      "Epoch: 100 - Loss: 0.0016626790165901184\n",
      "Epoch: 150 - Loss: 0.0013552707387134433\n",
      "Epoch: 200 - Loss: 0.0011757632018998265\n",
      "Epoch: 250 - Loss: 0.001062057912349701\n",
      "Epoch: 300 - Loss: 0.000978815252892673\n",
      "Epoch: 350 - Loss: 0.0009124271455220878\n",
      "Epoch: 400 - Loss: 0.0008648777729831636\n",
      "Epoch: 450 - Loss: 0.000824092305265367\n",
      "Epoch: 500 - Loss: 0.0007956300396472216\n",
      "Epoch: 550 - Loss: 0.0007687501492910087\n",
      "Epoch: 600 - Loss: 0.0007487469119951129\n",
      "Epoch: 650 - Loss: 0.0007269376656040549\n",
      "Epoch: 700 - Loss: 0.0007093211752362549\n",
      "Epoch: 750 - Loss: 0.0006911128293722868\n",
      "Epoch: 800 - Loss: 0.0006755587528459728\n",
      "Epoch: 850 - Loss: 0.0006615889142267406\n",
      "Epoch: 900 - Loss: 0.0006453979294747114\n",
      "Epoch: 950 - Loss: 0.0006339506944641471\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17669549584388733\n",
      "Epoch: 50 - Loss: 0.0022400999441742897\n",
      "Epoch: 100 - Loss: 0.0015536178834736347\n",
      "Epoch: 150 - Loss: 0.001248850952833891\n",
      "Epoch: 200 - Loss: 0.0010834434069693089\n",
      "Epoch: 250 - Loss: 0.0009792797500267625\n",
      "Epoch: 300 - Loss: 0.0008926891023293138\n",
      "Epoch: 350 - Loss: 0.0008324938826262951\n",
      "Epoch: 400 - Loss: 0.0007858777535147965\n",
      "Epoch: 450 - Loss: 0.0007477227482013404\n",
      "Epoch: 500 - Loss: 0.0007171756005845964\n",
      "Epoch: 550 - Loss: 0.0006945707718841732\n",
      "Epoch: 600 - Loss: 0.0006722733378410339\n",
      "Epoch: 650 - Loss: 0.0006531178369186819\n",
      "Epoch: 700 - Loss: 0.0006384409498423338\n",
      "Epoch: 750 - Loss: 0.0006238511996343732\n",
      "Epoch: 800 - Loss: 0.0006115634460002184\n",
      "Epoch: 850 - Loss: 0.0006002357695251703\n",
      "Epoch: 900 - Loss: 0.0005892948247492313\n",
      "Epoch: 950 - Loss: 0.0005792863667011261\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17578963935375214\n",
      "Epoch: 50 - Loss: 0.0025759139098227024\n",
      "Epoch: 100 - Loss: 0.0017799525521695614\n",
      "Epoch: 150 - Loss: 0.0014470412861555815\n",
      "Epoch: 200 - Loss: 0.0012512579560279846\n",
      "Epoch: 250 - Loss: 0.0011177068809047341\n",
      "Epoch: 300 - Loss: 0.0010124032851308584\n",
      "Epoch: 350 - Loss: 0.0009345595026388764\n",
      "Epoch: 400 - Loss: 0.0008758311741985381\n",
      "Epoch: 450 - Loss: 0.0008276618900708854\n",
      "Epoch: 500 - Loss: 0.0007822737097740173\n",
      "Epoch: 550 - Loss: 0.0007489107665605843\n",
      "Epoch: 600 - Loss: 0.000718010007403791\n",
      "Epoch: 650 - Loss: 0.0006943496409803629\n",
      "Epoch: 700 - Loss: 0.00067432428477332\n",
      "Epoch: 750 - Loss: 0.0006577662425115705\n",
      "Epoch: 800 - Loss: 0.000640353886410594\n",
      "Epoch: 850 - Loss: 0.0006235124310478568\n",
      "Epoch: 900 - Loss: 0.0006100933533161879\n",
      "Epoch: 950 - Loss: 0.000597083184402436\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.15639205276966095\n",
      "Epoch: 50 - Loss: 0.002280476735904813\n",
      "Epoch: 100 - Loss: 0.0016399153973907232\n",
      "Epoch: 150 - Loss: 0.0013819452142342925\n",
      "Epoch: 200 - Loss: 0.0012282101670280099\n",
      "Epoch: 250 - Loss: 0.0011249321978539228\n",
      "Epoch: 300 - Loss: 0.001045234501361847\n",
      "Epoch: 350 - Loss: 0.0009859658312052488\n",
      "Epoch: 400 - Loss: 0.0009310196619480848\n",
      "Epoch: 450 - Loss: 0.000894838129170239\n",
      "Epoch: 500 - Loss: 0.0008565050084143877\n",
      "Epoch: 550 - Loss: 0.0008300084737129509\n",
      "Epoch: 600 - Loss: 0.0008054292411543429\n",
      "Epoch: 650 - Loss: 0.0007839815807528794\n",
      "Epoch: 700 - Loss: 0.0007612883346155286\n",
      "Epoch: 750 - Loss: 0.0007453650468960404\n",
      "Epoch: 800 - Loss: 0.0007290106150321662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 850 - Loss: 0.000716599402949214\n",
      "Epoch: 900 - Loss: 0.000706146820448339\n",
      "Epoch: 950 - Loss: 0.0006945326458662748\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.18244224786758423\n",
      "Epoch: 50 - Loss: 0.002383534563705325\n",
      "Epoch: 100 - Loss: 0.001665937015786767\n",
      "Epoch: 150 - Loss: 0.0013599314261227846\n",
      "Epoch: 200 - Loss: 0.0011794946622103453\n",
      "Epoch: 250 - Loss: 0.0010512302396818995\n",
      "Epoch: 300 - Loss: 0.0009606469538994133\n",
      "Epoch: 350 - Loss: 0.0008958487887866795\n",
      "Epoch: 400 - Loss: 0.0008411644957959652\n",
      "Epoch: 450 - Loss: 0.00079882494173944\n",
      "Epoch: 500 - Loss: 0.0007660843548364937\n",
      "Epoch: 550 - Loss: 0.0007371437386609614\n",
      "Epoch: 600 - Loss: 0.000714646652340889\n",
      "Epoch: 650 - Loss: 0.0006948694353923202\n",
      "Epoch: 700 - Loss: 0.0006783563876524568\n",
      "Epoch: 750 - Loss: 0.0006631431169807911\n",
      "Epoch: 800 - Loss: 0.0006501146126538515\n",
      "Epoch: 850 - Loss: 0.0006378639372996986\n",
      "Epoch: 900 - Loss: 0.0006282342947088182\n",
      "Epoch: 950 - Loss: 0.0006135145085863769\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1624622344970703\n",
      "Epoch: 50 - Loss: 0.002485151868313551\n",
      "Epoch: 100 - Loss: 0.0018005723832175136\n",
      "Epoch: 150 - Loss: 0.0015020706923678517\n",
      "Epoch: 200 - Loss: 0.0013204163406044245\n",
      "Epoch: 250 - Loss: 0.0012036378029733896\n",
      "Epoch: 300 - Loss: 0.001112266443669796\n",
      "Epoch: 350 - Loss: 0.001039238297380507\n",
      "Epoch: 400 - Loss: 0.000978241441771388\n",
      "Epoch: 450 - Loss: 0.0009264682303182781\n",
      "Epoch: 500 - Loss: 0.000881546235177666\n",
      "Epoch: 550 - Loss: 0.0008424742263741791\n",
      "Epoch: 600 - Loss: 0.0008067808812484145\n",
      "Epoch: 650 - Loss: 0.0007789742667227983\n",
      "Epoch: 700 - Loss: 0.0007554065668955445\n",
      "Epoch: 750 - Loss: 0.000734921486582607\n",
      "Epoch: 800 - Loss: 0.000716791080776602\n",
      "Epoch: 850 - Loss: 0.0007033334695734084\n",
      "Epoch: 900 - Loss: 0.0006883707828819752\n",
      "Epoch: 950 - Loss: 0.0006769403698854148\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17657917737960815\n",
      "Epoch: 50 - Loss: 0.0023716886062175035\n",
      "Epoch: 100 - Loss: 0.0016923524672165513\n",
      "Epoch: 150 - Loss: 0.0013992199674248695\n",
      "Epoch: 200 - Loss: 0.001245760009624064\n",
      "Epoch: 250 - Loss: 0.0011384563986212015\n",
      "Epoch: 300 - Loss: 0.0010560104856267571\n",
      "Epoch: 350 - Loss: 0.000992475193925202\n",
      "Epoch: 400 - Loss: 0.000940228346735239\n",
      "Epoch: 450 - Loss: 0.0008955633384175599\n",
      "Epoch: 500 - Loss: 0.0008623257162980735\n",
      "Epoch: 550 - Loss: 0.0008308073156513274\n",
      "Epoch: 600 - Loss: 0.0008031360921449959\n",
      "Epoch: 650 - Loss: 0.000781600596383214\n",
      "Epoch: 700 - Loss: 0.0007585978601127863\n",
      "Epoch: 750 - Loss: 0.0007387868245132267\n",
      "Epoch: 800 - Loss: 0.0007213579374365509\n",
      "Epoch: 850 - Loss: 0.0007070082938298583\n",
      "Epoch: 900 - Loss: 0.0006904267356730998\n",
      "Epoch: 950 - Loss: 0.0006795543595217168\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1905689835548401\n",
      "Epoch: 50 - Loss: 0.002383633516728878\n",
      "Epoch: 100 - Loss: 0.0017158432165160775\n",
      "Epoch: 150 - Loss: 0.0014477524673566222\n",
      "Epoch: 200 - Loss: 0.0012976081343367696\n",
      "Epoch: 250 - Loss: 0.001196460914798081\n",
      "Epoch: 300 - Loss: 0.0011313727591186762\n",
      "Epoch: 350 - Loss: 0.0010809092782437801\n",
      "Epoch: 400 - Loss: 0.001034715212881565\n",
      "Epoch: 450 - Loss: 0.0010005006333813071\n",
      "Epoch: 500 - Loss: 0.0009714610641822219\n",
      "Epoch: 550 - Loss: 0.0009444414754398167\n",
      "Epoch: 600 - Loss: 0.0009230792638845742\n",
      "Epoch: 650 - Loss: 0.00090285629266873\n",
      "Epoch: 700 - Loss: 0.000880895706359297\n",
      "Epoch: 750 - Loss: 0.000864541856572032\n",
      "Epoch: 800 - Loss: 0.0008477819501422346\n",
      "Epoch: 850 - Loss: 0.0008292655693367124\n",
      "Epoch: 900 - Loss: 0.0008179962169378996\n",
      "Epoch: 950 - Loss: 0.0008031883626244962\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1910271793603897\n",
      "Epoch: 50 - Loss: 0.002728082239627838\n",
      "Epoch: 100 - Loss: 0.0019411578541621566\n",
      "Epoch: 150 - Loss: 0.0016332428203895688\n",
      "Epoch: 200 - Loss: 0.001460250117816031\n",
      "Epoch: 250 - Loss: 0.0013471900019794703\n",
      "Epoch: 300 - Loss: 0.0012677882332354784\n",
      "Epoch: 350 - Loss: 0.001201809966005385\n",
      "Epoch: 400 - Loss: 0.0011522448621690273\n",
      "Epoch: 450 - Loss: 0.0011078917887061834\n",
      "Epoch: 500 - Loss: 0.0010673735523596406\n",
      "Epoch: 550 - Loss: 0.0010333838872611523\n",
      "Epoch: 600 - Loss: 0.0010017016902565956\n",
      "Epoch: 650 - Loss: 0.0009736311621963978\n",
      "Epoch: 700 - Loss: 0.0009495860431343317\n",
      "Epoch: 750 - Loss: 0.0009283894905820489\n",
      "Epoch: 800 - Loss: 0.000909151800442487\n",
      "Epoch: 850 - Loss: 0.0008903337293304503\n",
      "Epoch: 900 - Loss: 0.0008713540155440569\n",
      "Epoch: 950 - Loss: 0.0008543341537006199\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1629742830991745\n",
      "Epoch: 50 - Loss: 0.0023519089445471764\n",
      "Epoch: 100 - Loss: 0.0016555212205275893\n",
      "Epoch: 150 - Loss: 0.001354127423837781\n",
      "Epoch: 200 - Loss: 0.0011764111695811152\n",
      "Epoch: 250 - Loss: 0.001053484040312469\n",
      "Epoch: 300 - Loss: 0.0009678463684394956\n",
      "Epoch: 350 - Loss: 0.0009005508618429303\n",
      "Epoch: 400 - Loss: 0.0008491600165143609\n",
      "Epoch: 450 - Loss: 0.0008079800172708929\n",
      "Epoch: 500 - Loss: 0.000773219158872962\n",
      "Epoch: 550 - Loss: 0.0007446735398843884\n",
      "Epoch: 600 - Loss: 0.0007201161934062839\n",
      "Epoch: 650 - Loss: 0.0006978125893510878\n",
      "Epoch: 700 - Loss: 0.0006819802802056074\n",
      "Epoch: 750 - Loss: 0.0006661327206529677\n",
      "Epoch: 800 - Loss: 0.0006501649040728807\n",
      "Epoch: 850 - Loss: 0.0006372930365614593\n",
      "Epoch: 900 - Loss: 0.0006257040658965707\n",
      "Epoch: 950 - Loss: 0.000616958481259644\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17517061531543732\n",
      "Epoch: 50 - Loss: 0.002601136453449726\n",
      "Epoch: 100 - Loss: 0.0018683917587623\n",
      "Epoch: 150 - Loss: 0.0015528014628216624\n",
      "Epoch: 200 - Loss: 0.0013668551109731197\n",
      "Epoch: 250 - Loss: 0.0012461855076253414\n",
      "Epoch: 300 - Loss: 0.0011488028103485703\n",
      "Epoch: 350 - Loss: 0.0010777576826512814\n",
      "Epoch: 400 - Loss: 0.0010213921777904034\n",
      "Epoch: 450 - Loss: 0.0009722791728563607\n",
      "Epoch: 500 - Loss: 0.0009315708302892745\n",
      "Epoch: 550 - Loss: 0.0009004406165331602\n",
      "Epoch: 600 - Loss: 0.0008750970009714365\n",
      "Epoch: 650 - Loss: 0.0008533522486686707\n",
      "Epoch: 700 - Loss: 0.0008286410593427718\n",
      "Epoch: 750 - Loss: 0.0008103972650133073\n",
      "Epoch: 800 - Loss: 0.0007942833472043276\n",
      "Epoch: 850 - Loss: 0.0007789365481585264\n",
      "Epoch: 900 - Loss: 0.00076469307532534\n",
      "Epoch: 950 - Loss: 0.0007532791933044791\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1550929993391037\n",
      "Epoch: 50 - Loss: 0.002380470745265484\n",
      "Epoch: 100 - Loss: 0.0017398414202034473\n",
      "Epoch: 150 - Loss: 0.0014523337595164776\n",
      "Epoch: 200 - Loss: 0.0012733623152598739\n",
      "Epoch: 250 - Loss: 0.0011505900183692575\n",
      "Epoch: 300 - Loss: 0.0010587614960968494\n",
      "Epoch: 350 - Loss: 0.0009896159172058105\n",
      "Epoch: 400 - Loss: 0.0009346192819066346\n",
      "Epoch: 450 - Loss: 0.0008890940807759762\n",
      "Epoch: 500 - Loss: 0.0008551314240321517\n",
      "Epoch: 550 - Loss: 0.0008261328912340105\n",
      "Epoch: 600 - Loss: 0.0008007336291484535\n",
      "Epoch: 650 - Loss: 0.000775340071413666\n",
      "Epoch: 700 - Loss: 0.0007539360085502267\n",
      "Epoch: 750 - Loss: 0.0007300690631382167\n",
      "Epoch: 800 - Loss: 0.0007141807000152767\n",
      "Epoch: 850 - Loss: 0.0006994546856731176\n",
      "Epoch: 900 - Loss: 0.0006862670416012406\n",
      "Epoch: 950 - Loss: 0.0006717970827594399\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1924905776977539\n",
      "Epoch: 50 - Loss: 0.0034613541793078184\n",
      "Epoch: 100 - Loss: 0.0024196424055844545\n",
      "Epoch: 150 - Loss: 0.001983590191230178\n",
      "Epoch: 200 - Loss: 0.0017353008734062314\n",
      "Epoch: 250 - Loss: 0.0015565021894872189\n",
      "Epoch: 300 - Loss: 0.0014311810955405235\n",
      "Epoch: 350 - Loss: 0.0013297941768541932\n",
      "Epoch: 400 - Loss: 0.001247782725840807\n",
      "Epoch: 450 - Loss: 0.001183295389637351\n",
      "Epoch: 500 - Loss: 0.0011248949449509382\n",
      "Epoch: 550 - Loss: 0.0010765903862193227\n",
      "Epoch: 600 - Loss: 0.0010366770438849926\n",
      "Epoch: 650 - Loss: 0.0010024987859651446\n",
      "Epoch: 700 - Loss: 0.0009701810195110738\n",
      "Epoch: 750 - Loss: 0.0009426766773685813\n",
      "Epoch: 800 - Loss: 0.0009169341647066176\n",
      "Epoch: 850 - Loss: 0.0008923600544221699\n",
      "Epoch: 900 - Loss: 0.0008718468016013503\n",
      "Epoch: 950 - Loss: 0.0008511341293342412\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1754855364561081\n",
      "Epoch: 50 - Loss: 0.0023929669987410307\n",
      "Epoch: 100 - Loss: 0.0016694576479494572\n",
      "Epoch: 150 - Loss: 0.0013547476846724749\n",
      "Epoch: 200 - Loss: 0.001168973627500236\n",
      "Epoch: 250 - Loss: 0.001038784859701991\n",
      "Epoch: 300 - Loss: 0.0009420450078323483\n",
      "Epoch: 350 - Loss: 0.0008737968164496124\n",
      "Epoch: 400 - Loss: 0.0008169312495738268\n",
      "Epoch: 450 - Loss: 0.0007723336457274854\n",
      "Epoch: 500 - Loss: 0.0007367802900262177\n",
      "Epoch: 550 - Loss: 0.0007078198250383139\n",
      "Epoch: 600 - Loss: 0.0006813794607296586\n",
      "Epoch: 650 - Loss: 0.0006569500546902418\n",
      "Epoch: 700 - Loss: 0.0006383750587701797\n",
      "Epoch: 750 - Loss: 0.0006211569998413324\n",
      "Epoch: 800 - Loss: 0.0006047516944818199\n",
      "Epoch: 850 - Loss: 0.0005944613949395716\n",
      "Epoch: 900 - Loss: 0.000585899455472827\n",
      "Epoch: 950 - Loss: 0.0005735583836212754\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17617550492286682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 - Loss: 0.0024254852905869484\n",
      "Epoch: 100 - Loss: 0.001698460429906845\n",
      "Epoch: 150 - Loss: 0.0013948738342151046\n",
      "Epoch: 200 - Loss: 0.0012213146546855569\n",
      "Epoch: 250 - Loss: 0.0011039874516427517\n",
      "Epoch: 300 - Loss: 0.0010138702346011996\n",
      "Epoch: 350 - Loss: 0.0009454736718907952\n",
      "Epoch: 400 - Loss: 0.0008881325484253466\n",
      "Epoch: 450 - Loss: 0.0008447114960290492\n",
      "Epoch: 500 - Loss: 0.0008105452870950103\n",
      "Epoch: 550 - Loss: 0.0007832199335098267\n",
      "Epoch: 600 - Loss: 0.0007566851563751698\n",
      "Epoch: 650 - Loss: 0.0007364132907241583\n",
      "Epoch: 700 - Loss: 0.0007165978895500302\n",
      "Epoch: 750 - Loss: 0.000702673802152276\n",
      "Epoch: 800 - Loss: 0.0006869733333587646\n",
      "Epoch: 850 - Loss: 0.0006762867560610175\n",
      "Epoch: 900 - Loss: 0.0006660722428932786\n",
      "Epoch: 950 - Loss: 0.0006550212274305522\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1824425905942917\n",
      "Epoch: 50 - Loss: 0.0033487901091575623\n",
      "Epoch: 100 - Loss: 0.002369505353271961\n",
      "Epoch: 150 - Loss: 0.001977580366656184\n",
      "Epoch: 200 - Loss: 0.001749497838318348\n",
      "Epoch: 250 - Loss: 0.0016007168451324105\n",
      "Epoch: 300 - Loss: 0.001487650559283793\n",
      "Epoch: 350 - Loss: 0.00140100484713912\n",
      "Epoch: 400 - Loss: 0.0013347743079066277\n",
      "Epoch: 450 - Loss: 0.0012748375302180648\n",
      "Epoch: 500 - Loss: 0.001223888946697116\n",
      "Epoch: 550 - Loss: 0.0011830090079456568\n",
      "Epoch: 600 - Loss: 0.0011442017275840044\n",
      "Epoch: 650 - Loss: 0.0011084979632869363\n",
      "Epoch: 700 - Loss: 0.001070395577698946\n",
      "Epoch: 750 - Loss: 0.0010410178219899535\n",
      "Epoch: 800 - Loss: 0.0010178704978898168\n",
      "Epoch: 850 - Loss: 0.0009952642722055316\n",
      "Epoch: 900 - Loss: 0.000974178547039628\n",
      "Epoch: 950 - Loss: 0.0009540574974380434\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17553582787513733\n",
      "Epoch: 50 - Loss: 0.002619571052491665\n",
      "Epoch: 100 - Loss: 0.0019088101107627153\n",
      "Epoch: 150 - Loss: 0.001602718373760581\n",
      "Epoch: 200 - Loss: 0.0014203126775100827\n",
      "Epoch: 250 - Loss: 0.0012964506167918444\n",
      "Epoch: 300 - Loss: 0.0012086165370419621\n",
      "Epoch: 350 - Loss: 0.0011379123898223042\n",
      "Epoch: 400 - Loss: 0.0010775357950478792\n",
      "Epoch: 450 - Loss: 0.0010223605204373598\n",
      "Epoch: 500 - Loss: 0.0009746356518007815\n",
      "Epoch: 550 - Loss: 0.0009328884771093726\n",
      "Epoch: 600 - Loss: 0.000896769983228296\n",
      "Epoch: 650 - Loss: 0.0008653486729599535\n",
      "Epoch: 700 - Loss: 0.000840555178001523\n",
      "Epoch: 750 - Loss: 0.0008139150450006127\n",
      "Epoch: 800 - Loss: 0.0007947342237457633\n",
      "Epoch: 850 - Loss: 0.0007779287407174706\n",
      "Epoch: 900 - Loss: 0.0007619576063007116\n",
      "Epoch: 950 - Loss: 0.0007466101669706404\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.1970469057559967\n",
      "Epoch: 50 - Loss: 0.002239225199446082\n",
      "Epoch: 100 - Loss: 0.0015620582271367311\n",
      "Epoch: 150 - Loss: 0.0012780337128788233\n",
      "Epoch: 200 - Loss: 0.0011197312269359827\n",
      "Epoch: 250 - Loss: 0.0010109874419867992\n",
      "Epoch: 300 - Loss: 0.0009432035149075091\n",
      "Epoch: 350 - Loss: 0.0008925588917918503\n",
      "Epoch: 400 - Loss: 0.0008463035337626934\n",
      "Epoch: 450 - Loss: 0.0008148833876475692\n",
      "Epoch: 500 - Loss: 0.000783342111390084\n",
      "Epoch: 550 - Loss: 0.0007536946213804185\n",
      "Epoch: 600 - Loss: 0.0007298343116417527\n",
      "Epoch: 650 - Loss: 0.0007088381098583341\n",
      "Epoch: 700 - Loss: 0.0006894923280924559\n",
      "Epoch: 750 - Loss: 0.0006741511751897633\n",
      "Epoch: 800 - Loss: 0.000657906464766711\n",
      "Epoch: 850 - Loss: 0.0006427025655284524\n",
      "Epoch: 900 - Loss: 0.000629671907518059\n",
      "Epoch: 950 - Loss: 0.0006152287242002785\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.17405720055103302\n",
      "Epoch: 50 - Loss: 0.002335069701075554\n",
      "Epoch: 100 - Loss: 0.0016534908208996058\n",
      "Epoch: 150 - Loss: 0.0013654367066919804\n",
      "Epoch: 200 - Loss: 0.0012016119435429573\n",
      "Epoch: 250 - Loss: 0.0010921384673565626\n",
      "Epoch: 300 - Loss: 0.0010071221040561795\n",
      "Epoch: 350 - Loss: 0.000945765757933259\n",
      "Epoch: 400 - Loss: 0.0008932952769100666\n",
      "Epoch: 450 - Loss: 0.000851957593113184\n",
      "Epoch: 500 - Loss: 0.0008174912072718143\n",
      "Epoch: 550 - Loss: 0.0007906727259978652\n",
      "Epoch: 600 - Loss: 0.0007611749460920691\n",
      "Epoch: 650 - Loss: 0.0007421245682053268\n",
      "Epoch: 700 - Loss: 0.0007245296146720648\n",
      "Epoch: 750 - Loss: 0.000709516869392246\n",
      "Epoch: 800 - Loss: 0.0006924830377101898\n",
      "Epoch: 850 - Loss: 0.0006837372202426195\n",
      "Epoch: 900 - Loss: 0.0006682040402665734\n",
      "Epoch: 950 - Loss: 0.000659323763102293\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.15661786496639252\n",
      "Epoch: 50 - Loss: 0.00317262951284647\n",
      "Epoch: 100 - Loss: 0.002375681884586811\n",
      "Epoch: 150 - Loss: 0.002048034453764558\n",
      "Epoch: 200 - Loss: 0.0018534549744799733\n",
      "Epoch: 250 - Loss: 0.0017205944750458002\n",
      "Epoch: 300 - Loss: 0.0016283276490867138\n",
      "Epoch: 350 - Loss: 0.0015511008678004146\n",
      "Epoch: 400 - Loss: 0.0014859306393191218\n",
      "Epoch: 450 - Loss: 0.0014328535180538893\n",
      "Epoch: 500 - Loss: 0.0013829937670379877\n",
      "Epoch: 550 - Loss: 0.001344751683063805\n",
      "Epoch: 600 - Loss: 0.001309606246650219\n",
      "Epoch: 650 - Loss: 0.0012726729037240148\n",
      "Epoch: 700 - Loss: 0.001243745326064527\n",
      "Epoch: 750 - Loss: 0.0012198520125821233\n",
      "Epoch: 800 - Loss: 0.0011983135482296348\n",
      "Epoch: 850 - Loss: 0.0011789248092100024\n",
      "Epoch: 900 - Loss: 0.0011618445860221982\n",
      "Epoch: 950 - Loss: 0.0011442898539826274\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.15926231443881989\n",
      "Epoch: 50 - Loss: 0.0026513217017054558\n",
      "Epoch: 100 - Loss: 0.0019704399164766073\n",
      "Epoch: 150 - Loss: 0.001686788978986442\n",
      "Epoch: 200 - Loss: 0.0015176520682871342\n",
      "Epoch: 250 - Loss: 0.0014024398988112807\n",
      "Epoch: 300 - Loss: 0.0013201565016061068\n",
      "Epoch: 350 - Loss: 0.0012552832486107945\n",
      "Epoch: 400 - Loss: 0.001202134764753282\n",
      "Epoch: 450 - Loss: 0.0011606530752032995\n",
      "Epoch: 500 - Loss: 0.0011196996783837676\n",
      "Epoch: 550 - Loss: 0.0010905432282015681\n",
      "Epoch: 600 - Loss: 0.0010617870138958097\n",
      "Epoch: 650 - Loss: 0.001036322908475995\n",
      "Epoch: 700 - Loss: 0.0010191769106313586\n",
      "Epoch: 750 - Loss: 0.0010016931919381022\n",
      "Epoch: 800 - Loss: 0.0009847902692854404\n",
      "Epoch: 850 - Loss: 0.0009690801962278783\n",
      "Epoch: 900 - Loss: 0.0009581875638104975\n",
      "Epoch: 950 - Loss: 0.0009463879396207631\n",
      "[1, 10, 0]\n",
      "Epoch: 0 - Loss: 0.15249566733837128\n",
      "Epoch: 50 - Loss: 0.0026860698126256466\n",
      "Epoch: 100 - Loss: 0.001977626932784915\n",
      "Epoch: 150 - Loss: 0.0016908157849684358\n",
      "Epoch: 200 - Loss: 0.0015326699940487742\n",
      "Epoch: 250 - Loss: 0.0014169981004670262\n",
      "Epoch: 300 - Loss: 0.0013314848765730858\n",
      "Epoch: 350 - Loss: 0.0012714393669739366\n",
      "Epoch: 400 - Loss: 0.001217530108988285\n",
      "Epoch: 450 - Loss: 0.0011787738185375929\n",
      "Epoch: 500 - Loss: 0.0011457190848886967\n",
      "Epoch: 550 - Loss: 0.0011131571372970939\n",
      "Epoch: 600 - Loss: 0.0010845058131963015\n",
      "Epoch: 650 - Loss: 0.0010553788160905242\n",
      "Epoch: 700 - Loss: 0.0010302033042535186\n",
      "Epoch: 750 - Loss: 0.0010071962606161833\n",
      "Epoch: 800 - Loss: 0.0009853931842371821\n",
      "Epoch: 850 - Loss: 0.0009672234882600605\n",
      "Epoch: 900 - Loss: 0.000948977074585855\n",
      "Epoch: 950 - Loss: 0.0009332671761512756\n"
     ]
    }
   ],
   "source": [
    "pr, re = [[],[],[]], [[],[],[]]\n",
    "lr = 0.001\n",
    "epochs = 1000\n",
    "constraintHigh=1\n",
    "constraintLow=0\n",
    "# constraintHigh=float('inf')\n",
    "# constraintLow=-float('inf')\n",
    "loss_weight = [1, 10, 0]\n",
    "L1, L2 = 1e-5, 0\n",
    "rand_type = 0\n",
    "\n",
    "total_mul = 1\n",
    "\n",
    "for uid, uemb in enumerate(tqdm(doc_embs[:100])):\n",
    "    x = word_embs.T\n",
    "    y = uemb\n",
    "    total = len(doc_answers[uid])\n",
    "\n",
    "    torch_model = PyTorchLinearRegression(x.shape[1], lr, constraintHigh, constraintLow, int(total*total_mul), rand_type, L1, L2)\n",
    "    torch_model.fit(x, y, epochs)\n",
    "    \n",
    "    m1 = metric4(torch_model.w.detach().numpy(), doc_answers[select_user], w_idx=None, topk=50, verbose=0)\n",
    "    m2 = metric4(torch_model.w.detach().numpy(), doc_answers[select_user], w_idx=None, topk=100, verbose=0)\n",
    "    m3 = metric4(torch_model.w.detach().numpy(), doc_answers[select_user], w_idx=None, topk=200, verbose=0)\n",
    "    pr[0].append(m1[\"precision\"])\n",
    "    re[0].append(m1[\"recall\"])\n",
    "    pr[1].append(m2[\"precision\"])\n",
    "    re[1].append(m2[\"recall\"])\n",
    "    pr[2].append(m3[\"precision\"])\n",
    "    re[2].append(m3[\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d270eb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.3566 Recall:0.1415\n",
      "Precision:0.2631 Recall:0.2088\n",
      "Precision:0.1834 Recall:0.2910\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision:{np.mean(pr[0]):.4f} Recall:{np.mean(re[0]):.4f}\")\n",
    "print(f\"Precision:{np.mean(pr[1]):.4f} Recall:{np.mean(re[1]):.4f}\")\n",
    "print(f\"Precision:{np.mean(pr[2]):.4f} Recall:{np.mean(re[2]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f94c6",
   "metadata": {},
   "source": [
    "## Top K freq word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "22532339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 137959),\n",
       " ('and', 71459),\n",
       " ('a', 66359),\n",
       " ('of', 61514),\n",
       " ('to', 52823),\n",
       " ('is', 45511),\n",
       " ('in', 39808),\n",
       " ('it', 31652),\n",
       " ('i', 29011),\n",
       " ('this', 27891)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = [(word, freq) for word, freq in dataset.vocab.word_freq_in_corpus.items()]\n",
    "word_freq.sort(key=lambda x:x[1], reverse=True)\n",
    "word_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ed91dff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac5fc008a8c449093d242c67ccef1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 50 word\n",
      "percision 0.57312\n",
      "recall 0.25995568997152513\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8456bb81126b4cbcb800069b5fb9bd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 100 word\n",
      "percision 0.42140999999999995\n",
      "recall 0.3705359126710024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff85c50d29541b486ede247d64d56d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 200 word\n",
      "percision 0.2830875\n",
      "recall 0.48635047389378483\n"
     ]
    }
   ],
   "source": [
    "def topk_word_evaluation(k=50):\n",
    "    topk_word = [word for (word, freq) in word_freq[:k]]\n",
    "\n",
    "    pr, re = [], []\n",
    "    for ans in tqdm(test_ans):\n",
    "        ans = set(ans)\n",
    "        ans = [dataset.vocab.itos[a] for a in ans]\n",
    "\n",
    "        hit = []\n",
    "        for word in ans:\n",
    "            if word in topk_word:\n",
    "                hit.append(word)\n",
    "\n",
    "        precision = len(hit) / k\n",
    "        recall = len(hit) / len(ans)\n",
    "        pr.append(precision)\n",
    "        re.append(recall)\n",
    "\n",
    "    print('top {} word'.format(k))\n",
    "    print('percision', np.mean(pr))\n",
    "    print('recall', np.mean(re))\n",
    "\n",
    "topk_word_evaluation(k=50)\n",
    "topk_word_evaluation(k=100)\n",
    "topk_word_evaluation(k=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeaca5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
